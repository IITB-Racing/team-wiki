{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"IIT Bombay Racing Team Wiki What this wiki contains This wiki stores & conveys the knowledge the driverless team has gained over the past few years. This contains the current progress of each subsystem, and also tries to discuss the journey of how we reached at this stage, which would be valuable for anyone in the team curious of why some of the decisions were made and help them make a faster decision over if they still make sense or not. We also have included 'Weekly priorities' page, which will be updated weekly with the team's task (with assigned person) & major priorities. This can be helpful for the alumuni's to get detailed info about what the team is working on + help us be focused on smaller goals to complete the larger goal. This wiki doesn't contain basic theoritical knowledge about any topic! (but we can combine them at one place though...\ud83e\udd14) Note This is our first version, and still not in a very finished state -- we appreciate any feedback on this (what more info can we include / should we change any structure /..) Project layout mkdocs.yml # The configuration file docs/ index.md # This wiki homepage goal.md # Goal for this year howto.md # Step wise guides for common tasks (in progress) updates.md # Weekly tasks perception/ overview.md # State of perception algos estimation/ overview.md # State of slam algos ekf.md # Details for our ekf algo mrpt.md # Details for MRPT library used controls/ overview.md # State of ppc algos planning.md # Logic for the path planning algo controls.md # Results & logic of controls algo sysint/ overview.md # Work done + to be done can.md # Explains CAN + work done with ADS-DV Why this wiki? build to convey context around our existing state + how did we arrive at this state easier to navigate through a subsystem topic & get the info fast! hoping, down the line this leads to better/faster decision making Team, major missing: Madhav, Arnav, Rohan, Shubham, Vishwam, Ayush (def need a new photo)","title":"Home"},{"location":"#iit-bombay-racing-team-wiki","text":"","title":"IIT Bombay Racing Team Wiki"},{"location":"#what-this-wiki-contains","text":"This wiki stores & conveys the knowledge the driverless team has gained over the past few years. This contains the current progress of each subsystem, and also tries to discuss the journey of how we reached at this stage, which would be valuable for anyone in the team curious of why some of the decisions were made and help them make a faster decision over if they still make sense or not. We also have included 'Weekly priorities' page, which will be updated weekly with the team's task (with assigned person) & major priorities. This can be helpful for the alumuni's to get detailed info about what the team is working on + help us be focused on smaller goals to complete the larger goal. This wiki doesn't contain basic theoritical knowledge about any topic! (but we can combine them at one place though...\ud83e\udd14) Note This is our first version, and still not in a very finished state -- we appreciate any feedback on this (what more info can we include / should we change any structure /..)","title":"What this wiki contains"},{"location":"#project-layout","text":"mkdocs.yml # The configuration file docs/ index.md # This wiki homepage goal.md # Goal for this year howto.md # Step wise guides for common tasks (in progress) updates.md # Weekly tasks perception/ overview.md # State of perception algos estimation/ overview.md # State of slam algos ekf.md # Details for our ekf algo mrpt.md # Details for MRPT library used controls/ overview.md # State of ppc algos planning.md # Logic for the path planning algo controls.md # Results & logic of controls algo sysint/ overview.md # Work done + to be done can.md # Explains CAN + work done with ADS-DV","title":"Project layout"},{"location":"#why-this-wiki","text":"build to convey context around our existing state + how did we arrive at this state easier to navigate through a subsystem topic & get the info fast! hoping, down the line this leads to better/faster decision making Team, major missing: Madhav, Arnav, Rohan, Shubham, Vishwam, Ayush (def need a new photo)","title":"Why this wiki?"},{"location":"dates/","text":"Key dates (FSAI'24) Below are the key dates for FSAI'24. Event Deadline FS Funding Awards Dec 1 Create Team Account / Those with existing team accounts ensure Faculty Advisor and Team Leader details are correct for FS2024 Dec 8 Design concept specification (no effort, ~0.5 page, template given / no points) Dec 8 Payments and Car Numbers accepted for teams selected to participate in 2024 competition Jan 19 - Feb 9 Autonomous Systems Responsible (ASR) (just the contact info of asr, template given) Feb 9 Autonomous System Form (ASF) (structured docs for AI computer and sensors, no template) Apr 1 Additional sensors CAD submission (zip containing CAD files, no template) Apr 1 Autonomous Design Report (ADR) May 9 Engineering Design Spec Sheet? (template will be made available) May 13 Change of Class from ADS to DDT (subject to capacity) May 19 Event programme images (Photographs and/or renders of your vehicle design plus university and team logos for inclusion in event programme) May 24 System Status Report (SSR) (template available) May 30 Attending live event confimation June 6 Apply for free IMechE membership if required June 19 Business Plan Presentation / Real World AI (+optional supporting docs) at the event","title":"Key dates"},{"location":"dates/#key-dates-fsai24","text":"Below are the key dates for FSAI'24. Event Deadline FS Funding Awards Dec 1 Create Team Account / Those with existing team accounts ensure Faculty Advisor and Team Leader details are correct for FS2024 Dec 8 Design concept specification (no effort, ~0.5 page, template given / no points) Dec 8 Payments and Car Numbers accepted for teams selected to participate in 2024 competition Jan 19 - Feb 9 Autonomous Systems Responsible (ASR) (just the contact info of asr, template given) Feb 9 Autonomous System Form (ASF) (structured docs for AI computer and sensors, no template) Apr 1 Additional sensors CAD submission (zip containing CAD files, no template) Apr 1 Autonomous Design Report (ADR) May 9 Engineering Design Spec Sheet? (template will be made available) May 13 Change of Class from ADS to DDT (subject to capacity) May 19 Event programme images (Photographs and/or renders of your vehicle design plus university and team logos for inclusion in event programme) May 24 System Status Report (SSR) (template available) May 30 Attending live event confimation June 6 Apply for free IMechE membership if required June 19 Business Plan Presentation / Real World AI (+optional supporting docs) at the event","title":"Key dates (FSAI'24)"},{"location":"goal/","text":"Goal 2024 Last season Highlights: We became the first team from India to participate in FSAI last season. We overall stood 12th among 19 teams. All our points came from static events. We were 3rd in Real world AI event. FSAI'23 Overall results Dynamics We were not expecting dynamic results, and had the main goal to successfully set-up communication with their ADS-DV car and clear inspections. We were able to achieve this, but there's one rule which we missed regarding inspection, The vehicle must sweep the steering left and right and return to straight. We planned to take a hunch at acceleration event, but couldn't participate as we couldn't get slot due to bad weather/rain. Statics We did very bad in the Simulation dev event - we failed to explain how, what we simulated with different simulators would translate to real life. Also we didn't prepare the presentaions well in ED & Sim dev, which led delay in the presentation time! Note More static feedback needs to be taken from Gopalan... This season FSAI final goal + strategy to achieve this + perfect opportunity to perform! This season too, we'll be going to participate in the same compitition - FSAI'24. Having sorted out communication with the car from last season + we being close to running full end-to-end pipeline + have every sensor/hardware we'll need, gives us a very good opportunity to aim big, bring back results! We're aiming to finish under overall top 3. For this we'll need atleast ~200 more points compared to last year, not an easy task! We'll earn these by improving on our mistakes in Engineering Design statics + Sim Dev. And for dynmaics, we'll put more priority on completing Accel & Skidpad events than Autocross / Trackdrive. This makes sure we're loosing easier points due to last minute workarounds to make accel/skidpad work!","title":"Goal 2024"},{"location":"goal/#goal-2024","text":"","title":"Goal 2024"},{"location":"goal/#last-season","text":"Highlights: We became the first team from India to participate in FSAI last season. We overall stood 12th among 19 teams. All our points came from static events. We were 3rd in Real world AI event. FSAI'23 Overall results","title":"Last season"},{"location":"goal/#dynamics","text":"We were not expecting dynamic results, and had the main goal to successfully set-up communication with their ADS-DV car and clear inspections. We were able to achieve this, but there's one rule which we missed regarding inspection, The vehicle must sweep the steering left and right and return to straight. We planned to take a hunch at acceleration event, but couldn't participate as we couldn't get slot due to bad weather/rain.","title":"Dynamics"},{"location":"goal/#statics","text":"We did very bad in the Simulation dev event - we failed to explain how, what we simulated with different simulators would translate to real life. Also we didn't prepare the presentaions well in ED & Sim dev, which led delay in the presentation time! Note More static feedback needs to be taken from Gopalan...","title":"Statics"},{"location":"goal/#this-season","text":"FSAI final goal + strategy to achieve this + perfect opportunity to perform! This season too, we'll be going to participate in the same compitition - FSAI'24. Having sorted out communication with the car from last season + we being close to running full end-to-end pipeline + have every sensor/hardware we'll need, gives us a very good opportunity to aim big, bring back results! We're aiming to finish under overall top 3. For this we'll need atleast ~200 more points compared to last year, not an easy task! We'll earn these by improving on our mistakes in Engineering Design statics + Sim Dev. And for dynmaics, we'll put more priority on completing Accel & Skidpad events than Autocross / Trackdrive. This makes sure we're loosing easier points due to last minute workarounds to make accel/skidpad work!","title":"This season"},{"location":"howto/","text":"How to guides How to use Lidar to get .pcd data Reflashing Jetson","title":"How to guides"},{"location":"howto/#how-to-guides","text":"How to use Lidar to get .pcd data Reflashing Jetson","title":"How to guides"},{"location":"updates/","text":"Weekly priorities Oct 10 - Oct 17 [13/33 = 39.39%] Sim dev setup in Carmaker @Mohak Vyas github repo setup \u2014 [P0 !!] (blocking!) \u274c should be able to launch carmaker easily - CM to alag se hi open karna padega \u2705 change topic names to common topic names chosen \u274c launch file for acceleration \u274c perception code missing, slam + ppc chala skte hain rn then try perception (as in fsds) acceleration map ready \u2014 [P0] (blocking!) \u274c ask in forums: \u2014 [P1] \u2705 lidar in CM? road pe white stripes? cones ke white stripes? Road pe white stripes / cone ke white stripes is sorted. Lidar isn't on CM yet, they'll be releasing it in the new version, to be realeased soon in Oct'23... able to get ground truth info (cones/car location, speed, \u2026) \u2014 [P1] \u2705 Acceleration ~~in carmaker~~ @Deep Boliya @Mohak Vyas goal: to complete under 5 sec in simulations improving accel based on to-dos \u2014 [P0] (blocking!) \u2705 [x] clamp steering (not do too much steering at any time) (ya to extreme case nahi aayega, ya recover nahi hoga) [x] autocross ke liye try karle best result we\u2019re getting rn is ~8sec port \u2192 carmaker \u2014 [P1] \u274c start impelementing \u2018alternate ways\u2019 \u2014 [P1] FSDS: seeing first few cones & interpolating to get boundary paths @rajit @ayush to stay within boundary, we\u2019ll need to know our location \u2192 use odometry interpolation with first few cones while gaadi static \u2705 implement tue controller \u274c initial cones might not be accurate enough \u2192 lines might not be very straight \u274c [ ] plot in rviz to test this Skidpad execution goal: to complete under 20 sec in simulations current to dos: make ppc code for this, same in both cases (try with/without error in car state) @ajinkya \u274c make slam/localization code ready, & try with known cone positions @arnav \u274c furhter to dos: try with mrpt, cones location unknown @Shreyash Gupta \u274c Perception specific able to run from a launch file (fix path error) @Yash Rampuria \u2014 [P0] (blocking!) \u2705 researching on how to: @Yash Rampuria \u2014 [P0] \u2705 improve range in stereo/mono pipeline? \u2192 using lidar improve latency in mono pipelines? \u2192 nn / mono (sift paused) using nueral network: @tangri \u2014 [P1] (avg error % = 4.15%) \u2705 training a neural network to find depth using bounding boxes data @rajit \u2014 [P1] \u2705 rn getting avg error % = 5.2% \u2192 scope for improvement but how much should error should we aim for? \u2192 run slam + ppc, with fake_meas + noise to check for this ig\u2026? lidar pipeline: @nakul \u2014 [P1] \u274c talk to @namitha? code chal rha hai, transformation matrices not correct probably, trying to fix it through calibration via matlab currently working on prev DEs ke code, fixing many errors\u2026 (not sure if transformation matrix is right) yolo retraining: @abhimanyu \u2014 [P1] sensors (zed / lidar) launch nahi hote everytime, bt dete h;ain mostly \u2705 blue/yellow cones ko bg classify kar rha hai - esp for far cones \u2192 will need more training with colab get help from @amit-sethi on training getting better results, orientation thresholds change karne hain ~~sift on gpu @rajit \u2014 [P0] (halted) ~~ oct 11: zed, cuda sab installed! Note \u2753 Mono giving different sizes of bounding box for one side \u2192 some bias in depth \u2192 perception + slam: deviating from straight. @Yash Rampuria what are we doing about this?? \u2014 retraining mono also sensors (zed / lidar) launch nahi hote everytime, bt dete hain? Slam specific root cause for data association issue (in fsds, with fake meas) \u2014 [P0] @Shreyash Gupta \u2705 update/correct full code according to a single ref by sunday (blocking!) (~1din aur) do a very structured root cause analysis graphslam @Shreyash Gupta @rohan \u2014 [P1] start writting some code for\u2026 (what should we aim for initially?) \u2705 include hone mein BT example code is running now onto how we can use that with out problem ~~porting fastslam \u2192 carmaker @Shreyash Gupta @arnav \u2014 [P1]~~ connecting perc to slam @rajit \u2014 [P1] \u274c better velocity estimation / odometry estimation method @amna \u2014 [P1] \u274c figuring out how to implement - need to learn KF? (as no direct implementation details) started implementing: (doubtful if we want to continue this further) PPC specific reading on mpc @Deep Boliya reading the math behind: it is an optimization problem \u2705 need more time to start implementing get & understand psuedo-transient model from @chandu @Deep Boliya \u274c implement Pure pursuit @shubham controller bacha hai ~1day implementing delaunay triangulation @shubham \u274c complete stanley implementation @ajinkya @ayush \u274c code likh liya hai for stanley, but error hai, starting mein right le rha hai oct 15: straight jaa rha hai but turn nahi le rha - ajinkya (knows root cause) cross error minimising \u2192 to the other side - mishra (knows root cause) Sys-int specific able to run iitbdv repo, with docker, on fsds rosbag (mono, mrpt, middle/raceline + accel) @bhaskar (blocking!) \u2705 on rosbag github actions \u2192 on push check if everything is building correctly explore CAN in carmaker @MG @vishwam \u274c ya to transfer deep \u2192 vishwam, aur liscense need ask @Ayush Rohilla \u2705 exploring: how to make our own simulator @MG @bhaskar \u274c eufs sim package documentation ~~sorting out github pull actions~~ + branch structure @MG Note \u2753 Lidar not on CM is a biggggg bt, should we be looking for backup in case CM delays their update? @Mohak Vyas Jetson \u2014 [P0] not booting up, try reinstalling / force recovery mode ubuntu (blocking!) \u274c Team wiki completion \u2014 [P2] Perception: incorporate the feedbacks, more pages? @Yash Rampuria \u274c @abhimanyu karega ab SLAM: complete MRPT page @Shreyash Gupta \u274c ye to shreyash to hi karna padega Sys int: incorporate the feedbacks, more pages (simulatation, bot), ~~docker @bhaskar~~ @Mohak Vyas @MG \u274c Ideation on Trainee modules - [P2] Recruitment might start late. Need a different/structured recruitment + trainee module plan so that: reach more freshers, when we\u2019re starting recruitment late? min effort by team (a lot of time/effort goes for debugging errors / installing in the modules) structured week-by-week content with assignments documented on docs / github meeting with trainees one time a week? a good efficient outcome (we gave 4 months, but they still some have installation issues + need to more training to be able to contribute to their subsystem). should we spend less time in modules, and make JDEs faster so they\u2019ve more time to learn their subsytems? how to improve SLAM module? - no first pref till now \u2639\ufe0f to do: need to work on the overall structure and req. / what changes can be made @Ayush Rohilla \u274c Open questions what all data (& where) do we\u2019ve collected from ads-dv from last season? 5 accel 2 zig zag pen drives mein hai but online nahi upload kar skte\u2026 need to buy a hard drive compatible with in-car pc : https://github.com/FS-AI/FS-AI_Compute/issues/1 do we know what was going wrong ab tak in meas_update? probably kaafi mix match tha logic mein, even le large had some error in their code Oct 2 - Oct 9 [7/30 = 23.33%] Sim dev setup in Carmaker @Mohak Vyas github repo setup \u2014 [P0 !!] (blocking!) \u274c should be able to launch carmaker easily change topic names to common topic names chosen launch file for acceleration acceleration map ready \u2014 [P1] (blocking!) \u274c ask in forums: \u2014 [P0] \u274c lidar in CM? cones/road pe white stripes? able to get ground truth info (cones/car location, speed, \u2026) \u2014 [P1] \u274c Acceleration in carmaker @Deep Boliya @Mohak Vyas goal: to complete under 5 sec in simulations (For FSAI: 0.3m from starting line, 75m track length, 3m wide, 100m stopping length) improving accel based on to-dos \u2014 [P0] \u2705 [x] tuning the pid [x] improving controller \u2192 differential one [ ] clamp steering (not do too much steering at any time) (ya to extreme case nahi aayega, ya recover nahi hoga) [x] start mein teda krke chala ke dekho\u2026 [ ] autocross ke liye try karle start impelementing \u2018alternate ways\u2019 \u2014 [P1] \u274c FSDS: seeing first few cones & interpolating to get boundary paths @rajit @ayush to stay within boundary, we\u2019ll need to know our location \u2192 use odometry initial cones might not be accurate enough \u2192 lines might not be very straight [ ] plot in rviz to test this port \u2192 carmaker \u2014 [P1] \u274c Skidpad ideation goal: to complete under 20 sec in simulations ((FSG\u201922) The foremost part of the vehicle is staged 15m before the timekeeping line. Pehle right - second lap on right turn is timed. Then left turn - fourth lap on left is timed. must come to a full stop within 25m after crossing the timekeeping line) come up with ways we can complete skidpad \u2014 [P0] @Ayush Rohilla @DEs \u2705 Note assuming the map is placed as per the diagram: perc: mono / best pipeline (as bohut saare cones ek saath, time le skta hai to compute) slam: ekf localization to be figured out @Shreyash Gupta \u2014 hai ek library with feature map option\u2026 ppc: we know the boundaries either way, so we\u2019ll know what middle path to follow perc: same slam: try with mrpt, range ~15m; can we alter the meas coming in so that cones given by perception always lie on boundary? sounds fishy. assuming the map isn\u2019t placed as per the diagram (but boundaries same): ppc: same next to-dos: make ppc code for this, same in both cases (try with/without error in car state) @ajinkya try with mrpt, cones location unknown @Shreyash Gupta make slam/localization code ready, & try with known cone positions @arnav Perception specific able to run from a launch file (fix path error) @Yash Rampuria \u2014 [P0] (blocking!) \u274c researching on how to: @Yash Rampuria \u2014 [P0] \u274c improve range in stereo/mono pipeline? improve latency in mono pipelines? using nueral network: @tangri \u2014 [P0] \u274c lidar pipeline: @nakul \u2014 [P1] \u274c Find u v of a cone centre approximately and using step 3 ka result, find corresponding depth: ~2-3 days \u2705 nan values error \u2192 last year code lookup; ~2-3 days (nakul ka code, not continuing) talk to @namitha? currently working on prev DEs ke code, fixing many errors\u2026 (not sure if transformation matrix is right) working on: we\u2019ll take depth from lidar + use cam for classification (not only lidar pipeline\u2026) yolo retraining: @abhimanyu \u2014 [P1] sensors (zed / lidar) launch nahi hote everytime, bt dete hain \u274c blue/yellow cones ko bg classify kar rha hai - esp for far cones same cone pe do bounding boxes \u2192 non-max suppression threshold change (v5 pe hat gye the) \u2705 will try yoloV8: more stable \u2192 thode better results \u2192 have to train on better resolutions on colab \u2705 get help from @amit-sethi on training will need more training with colab sift on gpu @rajit \u2014 [P0] (blocking!) \u2705 zed, cuda sab installed! Note \u2753 Mono giving different sizes of bounding box for one side \u2192 some bias in depth \u2192 perception + slam: deviating from straight. @Yash Rampuria what are we doing about this?? \u2014 retraining mono + sensors (zed / lidar) launch nahi hote everytime, bt dete hain Slam specific root cause for data association issue (in fsds, with fake meas) \u2014 [P0] @Shreyash Gupta \u274c update/correct full code according to a single ref by sunday (blocking!) (~1din aur) do a very structured root cause analysis graphslam @Shreyash Gupta @rohan \u2014 [P1] figure out g2o & graphslam implementation (g2o, \u2026?) \u2705 understanding the example slam2d what is input & output format???? start writting some code for\u2026 (what should we aim for initially?) \u274c include hone mein BT lelarge waala paper padh le - compares ekf slam vs graphslam \u2705 EKF SLAM vs GraphSLAM ~~porting fastslam \u2192 carmaker @Shreyash Gupta @arnav \u2014 [P1]~~ connecting perc to slam @rajit \u2014 [P1] \u274c better velocity estimation / odometry estimation method @amna \u2014 [P1] \u2705 rnn *1layer vs 2layer, *mkf with sensors: mkf is best, rnn 1layer is similar rnn 1 layer: motor encoder, two imu (?) , gnss mkf.. ke sensors? struggling to get implementation details PPC specific get & understand psuedo-transient model from @chandu @Deep Boliya \u274c plan on delaunay triangulation @deep \u2705 implementing @shubham Complete stanley implementation @ajinkya @ayush \u274c ~2 days code likh liya hai for stanley, but error hai, starting mein right le rha hai ~~get fsds working with ros bridge~~ and implement Pure pursuit @shubham \u274c ~~get fsds working, core dumped @ayush (blocking!) ~~ Note \ud83d\udccc JDEs trying to implement ppc without looking into code, interpolating + stanley controller + vel profile / pure-pursuit ~ 3-4 more days. They\u2019re coming with some new ideas to implement. Sys-int specific able to run iitbdv repo, with docker, on fsds rosbag (mono, mrpt, middle/raceline + accel) @bhaskar (blocking!) \u274c figuring out gui in ros docker \u2705 figure out how to sync docker files/images?? - does whole 14gb docker image get \u2192 only parts, not whole \u2705 kaburnates\u2026 managing docker files? (for multiple docker) \u2705 on rosbag github actions \u2192 on push check if everything is building correctly explore CAN in carmaker @MG @vishwam \u274c ya to transfer deep \u2192 vishwam, aur liscense need ask @Ayush Rohilla exploring: how to make our own simulator @MG \u274c Note \u2753 carmaker: cone ke white stripes nahi hone chahiye, road ke white stripes se interfere (have cone models with black stripes) @Mohak Vyas. Will we be able to do this? \u2014 ask on forum Jetson \u2014 [P0] \u274c not booting up, try reinstalling / force recovery mode ubuntu @Mohak Vyas @vishwam (blocking!) Team wiki completion \u2014 [P2] \u274c Perception: incorporate the feedbacks, more pages? @Yash Rampuria SLAM: complete MRPT page @Shreyash Gupta Sys int: incorporate the feedbacks, more pages (simulatation, bot) @Mohak Vyas @MG Ideation on Trainee modules - [P2] \u274c Recruitment might start late. Need a different/structured recruitment + trainee module plan so that: reach more freshers, when we\u2019re starting recruitment late? min effort by team (a lot of time/effort goes for debugging errors / installing in the modules) structured week-by-week content with assignments documented on docs / github meeting with trainees one time a week? a good efficient outcome (we gave 4 months, but they still some have installation issues + need to more training to be able to contribute to their subsystem). should we spend less time in modules, and make JDEs faster so they\u2019ve more time to learn their subsytems? how to improve SLAM module? - no first pref till now \u2639\ufe0f React \ud83c\udfce\ufe0f to the whatsapp msg, if you\u2019ve carefully read & acknowledged the priorities for this week. Sept 26 - Oct 1 [12/27 = 44%] Sim dev setup in Carmaker @Mohak Vyas \u274c github repo setup \u2014 [P0 !!] should be able to launch carmaker easily change topic names to common topic names chosen launch file for acceleration able to get ground truth info (cones/car location, speed, \u2026) \u2014 [P0] acceleration map ready \u2014 [P0] Acceleration in carmaker @Deep Boliya 0.3m from starting line, 75m track length, 3m wide, 100m stopping length list alternative ways to complete acceleration \u2014 [P0] \u2705 seeing first few cones & interpolating to get boundary paths to stay within boundary, we\u2019ll need to know our location \u2192 use odometry initial cones might not be accurate enough \u2192 lines might not be very straight [ ] plot in rviz to test this using Lidar only orientation based on assumption that car is staged centered + we can get accurate yaw for a while from imu bearing method (fix the stopping position, Thu night) \u2192 carmaker \u2014 [P0] \u2705 what are possible wrong outcomes, with this implementation? on ads-dv will need to aim for an ideal speed to follow, such that pts max + are able to stop safely within 100m (depends on the stopping potential) Note \ud83d\ude80 FSDS mein: speed 4ms se zyaada nhi off track jaate hi gone case can we use orientation of car to further improve this?? using total distance travelled as stopping logic\u2026 assuming distance from encoder data to be pretty acurate (as per deep\u2019s experience with ADS-DV), if ads-dv isn\u2019t giving accurate distance tune it there to go more than 75m or less than 75m as req\u2026 further to dos: start mein teda krke chala ke dekho\u2026 AS_FINISH logic, and successfully return \u2018AS_FINSIH\u2019 on terminal - can be done when we port \u2192 Carmaker tuning the pid improving controller \u2192 differential one clamp steering (not do too much steering at any time) (ya to extreme case nahi aayega ya recover nahi hoga) weighted sum with orientation (not much weight) if off track: yellow/blue identify karke make a turn (if speed is enough, we might not have enough time to see all yellow & deicide to make a turn) start impelementing \u2018alternate ways\u2019 \u2014 [P1] \u274c Perception specific able to run from a launch file (fix path error) @Yash Rampuria \u2014 [P0] \u274c researching on how to: @Yash Rampuria \u2014 [P1] \u274c improve latency in mono pipelines? improve range in stereo/mono pipeline? lidar pipeline: @nakul @abhimanyu \u2014 [P1] Put the transformation matrix in a variable as a multiplication of 3 4 different transformations (exteinsic intrinsic etc) \u2705 Learn how to read pcd data \u2705 Pcd has data in the format (x y z I) and u need to convert it to (u v depth) \u2705 Find u v of a cone centre approximately and using step 3 ka result, find corresponding depth - ~ 2-3 days \u274c sift on gpu @rajit - driver error \u274c Note \u2753 Mono giving different sizes of bounding box for one side \u2192 some bias in depth \u2192 perception + slam: deviating from straight. @Yash Rampuria what are we doing about this?? Slam specific root cause for data association issue (in fsds, with fake meas) \u2014 [P0] @Shreyash Gupta \u274c graphslam: come up with a plan @Shreyash Gupta @rohan \u2014 [P1] collect resources \u2705 get overview of the algo \u2705 examples on how it can be implemented (g2o, \u2026?) \u274c porting fastslam \u2192 carmaker @Shreyash Gupta @arnav\u2014 [P1] \u274c better velocity estimation method @amna \u2014 [P1] \u274c ~~porting mrpt \u2192 carmaker??? (ho rakha hai)~~ PPC specific @Deep Boliya to add jde tasks for this week \u274c Note \ud83d\udccc JDEs trying to implement ppc without looking into code, interpolating + stanley controller + vel profile / pure-pursuit ~ 3-4 more days. Through this they\u2019re coming with some new ideas to implement. Sys-int specific ros2 karna hai ki nahi? (~1-2 din mein decide) \u2014 [P1] @Mohak Vyas \u2705 nahi for now: faaltu bt nhi lena hai / ros2 has a better way to send msgs than ros1 (less delays due to truely parallel architecture) / ros1 noetic eol in 2025, have two years atleast / we\u2019re all familiar with ros1, will take some to get used to ros2 as well docker: plan for integrating (~1-2 din) \u2014 [P0] @MG @jdes \u2705 what should the final output be like? (what all will it \u2018contain\u2019? system requirements, probably require nvidia graphic cards?) things the docker should contain https://docs.google.com/document/d/1ojJ-bONWIKGVy3xhxL1UiQXZqVMYcOj-czewkg0QXAo/edit Note \u2753 carmaker: cone ke white stripes nahi hone chahiye, road ke white stripes se interfere (have cone models with black stripes) @Mohak Vyas. Will we be able to do this? Jetson \u2014 [P0] not booting up, try reinstalling / force recovery mode ubuntu @Mohak Vyas \u274c reach out to nvidia/help center/\u2026 @Ayush Rohilla \u2705 reaching out through forums - suggesting same, that we should reflash our board with sdkmanager from another x86 host https://forums.developer.nvidia.com/t/jetson-agx-orin-not-booting-up/267798 trying force recovery mode - https://forums.developer.nvidia.com/t/agx-orin-not-booting/258038 Team wiki completion \u2014 [P1] Perception: incorporate the feedbacks, more pages? @Yash Rampuria \u274c SLAM: complete MRPT page @Shreyash Gupta \u274c Sys int: incorporate the feedbacks, more pages (simulatation, bot) @Mohak Vyas @MG \u274c Overview: home, goal & vision 2024, ~~compi 101~~, ~~culture?~~ @Ayush Rohilla \u2705 Local to web, using github hosting, (any method to keep it private!??) @Ayush Rohilla \u2705 github host from org - not possible, with a personal account, public repo - host possible need to search for alternate tools for free private github pages -- static.app/sites fast enough (https://lime-otter.static.domains/) Doubts whats stopping us to use Windows instead of linux (LOL had existential crisis for a min)? \u2014 jetson mein linux hota hai Sept 13 - Sept 25 Midsem break Sept 4 - Sept 12 [10/20 = 50%] Metric targets for perception/slam/ppc to reach for a successfull integration @DEs @Ayush Rohilla \u2014 [P0] Perception: accuracy, range, outlier%, latency \u2705 currently we\u2019re at - range<10m (less than two pairs of cones visible), latency bad for stereo with sift, avg error ~3.38% for mono Range: <10m \u2192 15+m Latency: 2-3sec / 100ms \u2192 50ms (20hz) Avg error: ?? SLAM: mean squared error, cone count, matching ratio, error threshold, latency of output to ppc \u274c currently we\u2019re at - min range that works is~20m with custom_meas of super accuracy, at about ~2m/s max velocity \u2014 nahi to it\u2019s not able to complete the whole lap were getting mean squared error of ~0.01 m^2, correct cone count for a lap (didn\u2019t calculate matching ratio / error threshold yet), latency ~100hz with update from meas ~20hz (noisy fake_meas ke saath try\u2026.) why multiple freq in IMU? extra cones being identified discuss with @Shreyash Gupta PPC: time taken in each type of event (also our north star metric), cones hit, max vel/accln raceline: 32sec, firstlap: ? (range se input leke) \u2705 cones hit: 0, max vel: ?, max accel: ? accln: ~6-7 sec, skidpad: ~30sec, trackdrive: ~1min (+-20sec), fastlap: fsai mein to slow slow hi (check fsg timings) can PPC take & use gridmap??? (mainly frequency pe hi depend karega output, given error itna hai ki it can complete event) Tentative targets in simulations Accln: 5sec Skidpad: 20sec Autocross: 45sec Trackdrive: 35sec SLAM - which algorithms to prioritize on? (tough question!) @Shreyash Gupta @Ayush Rohilla \u2014 [P0] \u2705 EKF meas mein use fake meas FSDS\u2026 (can debug) \u2014 root cause??? fastSLAM \u2014 port to FSDS (from fssim) graphslam \u2014 what is g2o / how to implement? mrpt \u2014 localization with range bearing (if possible) Which simulator to continue on? Carmaker (global cones position/route coordinates? & IMU sensor add?) @Mohak Vyas \u2014 [P0] \u2705 FSDS (depthmap isn\u2019t correct!) @Mohak Vyas @Yash Rampuria \u2014 [P1] \u274c FSSIM (why did we discontinue this + current state?) @Ayush Rohilla \u2014 [P1] \u274c Steps to create our own simulator @Mohak Vyas \u2014 [P2] \u274c Different strategies to complete Accln Other ways to do accln?? \u2014 [P0] \u274c Perc + PPC (with no slam) finish implementing @Yash Rampuria @Deep Boliya \u2014 [P1] \u2705 Jetson status\u2026 @Deep Boliya @Mohak Vyas @Ayush Rohilla \u2014 [P0] \u2705 send to Nvidia if broken / we can\u2019t fix it :( not booting up, try reinstalling os +have reach out to nvidia JDE KTs (knowledge transfer) @DEs @JDEs \u2014 [P0] \u2705 we want all JDEs to be able to contribute to the team asap!! have started giving them real tasks as well\u2026 Team wiki completion \u2014 [P1] Perception: incorporate the feedbacks, more pages? @Yash Rampuria \u274c SLAM: complete MRPT page @Shreyash Gupta \u274c PPC: incorporate the feedbacks, add vehicle dynamics/controls/ads-dv page @Deep Boliya \u2705 Sys int: incorporate the feedbacks, more pages (simulatation, bot) @Mohak Vyas @MG \u274c Overview: home, goal & vision 2024, compi 101, culture? @Ayush Rohilla \u274c Local to web, using github hosting @Ayush Rohilla \u274c Sys architecture + repo structure @DEs @Ayush Rohilla \u2014 [P1] \u2705 Rulebook prep for quiz on Sat @DEs @JDEs \u2014 [P1] \u2705","title":"Weekly priorities"},{"location":"updates/#weekly-priorities","text":"","title":"Weekly priorities"},{"location":"updates/#oct-10-oct-17-1333-3939","text":"Sim dev setup in Carmaker @Mohak Vyas github repo setup \u2014 [P0 !!] (blocking!) \u274c should be able to launch carmaker easily - CM to alag se hi open karna padega \u2705 change topic names to common topic names chosen \u274c launch file for acceleration \u274c perception code missing, slam + ppc chala skte hain rn then try perception (as in fsds) acceleration map ready \u2014 [P0] (blocking!) \u274c ask in forums: \u2014 [P1] \u2705 lidar in CM? road pe white stripes? cones ke white stripes? Road pe white stripes / cone ke white stripes is sorted. Lidar isn't on CM yet, they'll be releasing it in the new version, to be realeased soon in Oct'23... able to get ground truth info (cones/car location, speed, \u2026) \u2014 [P1] \u2705 Acceleration ~~in carmaker~~ @Deep Boliya @Mohak Vyas goal: to complete under 5 sec in simulations improving accel based on to-dos \u2014 [P0] (blocking!) \u2705 [x] clamp steering (not do too much steering at any time) (ya to extreme case nahi aayega, ya recover nahi hoga) [x] autocross ke liye try karle best result we\u2019re getting rn is ~8sec port \u2192 carmaker \u2014 [P1] \u274c start impelementing \u2018alternate ways\u2019 \u2014 [P1] FSDS: seeing first few cones & interpolating to get boundary paths @rajit @ayush to stay within boundary, we\u2019ll need to know our location \u2192 use odometry interpolation with first few cones while gaadi static \u2705 implement tue controller \u274c initial cones might not be accurate enough \u2192 lines might not be very straight \u274c [ ] plot in rviz to test this Skidpad execution goal: to complete under 20 sec in simulations current to dos: make ppc code for this, same in both cases (try with/without error in car state) @ajinkya \u274c make slam/localization code ready, & try with known cone positions @arnav \u274c furhter to dos: try with mrpt, cones location unknown @Shreyash Gupta \u274c Perception specific able to run from a launch file (fix path error) @Yash Rampuria \u2014 [P0] (blocking!) \u2705 researching on how to: @Yash Rampuria \u2014 [P0] \u2705 improve range in stereo/mono pipeline? \u2192 using lidar improve latency in mono pipelines? \u2192 nn / mono (sift paused) using nueral network: @tangri \u2014 [P1] (avg error % = 4.15%) \u2705 training a neural network to find depth using bounding boxes data @rajit \u2014 [P1] \u2705 rn getting avg error % = 5.2% \u2192 scope for improvement but how much should error should we aim for? \u2192 run slam + ppc, with fake_meas + noise to check for this ig\u2026? lidar pipeline: @nakul \u2014 [P1] \u274c talk to @namitha? code chal rha hai, transformation matrices not correct probably, trying to fix it through calibration via matlab currently working on prev DEs ke code, fixing many errors\u2026 (not sure if transformation matrix is right) yolo retraining: @abhimanyu \u2014 [P1] sensors (zed / lidar) launch nahi hote everytime, bt dete h;ain mostly \u2705 blue/yellow cones ko bg classify kar rha hai - esp for far cones \u2192 will need more training with colab get help from @amit-sethi on training getting better results, orientation thresholds change karne hain ~~sift on gpu @rajit \u2014 [P0] (halted) ~~ oct 11: zed, cuda sab installed! Note \u2753 Mono giving different sizes of bounding box for one side \u2192 some bias in depth \u2192 perception + slam: deviating from straight. @Yash Rampuria what are we doing about this?? \u2014 retraining mono also sensors (zed / lidar) launch nahi hote everytime, bt dete hain? Slam specific root cause for data association issue (in fsds, with fake meas) \u2014 [P0] @Shreyash Gupta \u2705 update/correct full code according to a single ref by sunday (blocking!) (~1din aur) do a very structured root cause analysis graphslam @Shreyash Gupta @rohan \u2014 [P1] start writting some code for\u2026 (what should we aim for initially?) \u2705 include hone mein BT example code is running now onto how we can use that with out problem ~~porting fastslam \u2192 carmaker @Shreyash Gupta @arnav \u2014 [P1]~~ connecting perc to slam @rajit \u2014 [P1] \u274c better velocity estimation / odometry estimation method @amna \u2014 [P1] \u274c figuring out how to implement - need to learn KF? (as no direct implementation details) started implementing: (doubtful if we want to continue this further) PPC specific reading on mpc @Deep Boliya reading the math behind: it is an optimization problem \u2705 need more time to start implementing get & understand psuedo-transient model from @chandu @Deep Boliya \u274c implement Pure pursuit @shubham controller bacha hai ~1day implementing delaunay triangulation @shubham \u274c complete stanley implementation @ajinkya @ayush \u274c code likh liya hai for stanley, but error hai, starting mein right le rha hai oct 15: straight jaa rha hai but turn nahi le rha - ajinkya (knows root cause) cross error minimising \u2192 to the other side - mishra (knows root cause) Sys-int specific able to run iitbdv repo, with docker, on fsds rosbag (mono, mrpt, middle/raceline + accel) @bhaskar (blocking!) \u2705 on rosbag github actions \u2192 on push check if everything is building correctly explore CAN in carmaker @MG @vishwam \u274c ya to transfer deep \u2192 vishwam, aur liscense need ask @Ayush Rohilla \u2705 exploring: how to make our own simulator @MG @bhaskar \u274c eufs sim package documentation ~~sorting out github pull actions~~ + branch structure @MG Note \u2753 Lidar not on CM is a biggggg bt, should we be looking for backup in case CM delays their update? @Mohak Vyas Jetson \u2014 [P0] not booting up, try reinstalling / force recovery mode ubuntu (blocking!) \u274c Team wiki completion \u2014 [P2] Perception: incorporate the feedbacks, more pages? @Yash Rampuria \u274c @abhimanyu karega ab SLAM: complete MRPT page @Shreyash Gupta \u274c ye to shreyash to hi karna padega Sys int: incorporate the feedbacks, more pages (simulatation, bot), ~~docker @bhaskar~~ @Mohak Vyas @MG \u274c Ideation on Trainee modules - [P2] Recruitment might start late. Need a different/structured recruitment + trainee module plan so that: reach more freshers, when we\u2019re starting recruitment late? min effort by team (a lot of time/effort goes for debugging errors / installing in the modules) structured week-by-week content with assignments documented on docs / github meeting with trainees one time a week? a good efficient outcome (we gave 4 months, but they still some have installation issues + need to more training to be able to contribute to their subsystem). should we spend less time in modules, and make JDEs faster so they\u2019ve more time to learn their subsytems? how to improve SLAM module? - no first pref till now \u2639\ufe0f to do: need to work on the overall structure and req. / what changes can be made @Ayush Rohilla \u274c Open questions what all data (& where) do we\u2019ve collected from ads-dv from last season? 5 accel 2 zig zag pen drives mein hai but online nahi upload kar skte\u2026 need to buy a hard drive compatible with in-car pc : https://github.com/FS-AI/FS-AI_Compute/issues/1 do we know what was going wrong ab tak in meas_update? probably kaafi mix match tha logic mein, even le large had some error in their code","title":"Oct 10 - Oct 17 [13/33 = 39.39%]"},{"location":"updates/#oct-2-oct-9-730-2333","text":"Sim dev setup in Carmaker @Mohak Vyas github repo setup \u2014 [P0 !!] (blocking!) \u274c should be able to launch carmaker easily change topic names to common topic names chosen launch file for acceleration acceleration map ready \u2014 [P1] (blocking!) \u274c ask in forums: \u2014 [P0] \u274c lidar in CM? cones/road pe white stripes? able to get ground truth info (cones/car location, speed, \u2026) \u2014 [P1] \u274c Acceleration in carmaker @Deep Boliya @Mohak Vyas goal: to complete under 5 sec in simulations (For FSAI: 0.3m from starting line, 75m track length, 3m wide, 100m stopping length) improving accel based on to-dos \u2014 [P0] \u2705 [x] tuning the pid [x] improving controller \u2192 differential one [ ] clamp steering (not do too much steering at any time) (ya to extreme case nahi aayega, ya recover nahi hoga) [x] start mein teda krke chala ke dekho\u2026 [ ] autocross ke liye try karle start impelementing \u2018alternate ways\u2019 \u2014 [P1] \u274c FSDS: seeing first few cones & interpolating to get boundary paths @rajit @ayush to stay within boundary, we\u2019ll need to know our location \u2192 use odometry initial cones might not be accurate enough \u2192 lines might not be very straight [ ] plot in rviz to test this port \u2192 carmaker \u2014 [P1] \u274c Skidpad ideation goal: to complete under 20 sec in simulations ((FSG\u201922) The foremost part of the vehicle is staged 15m before the timekeeping line. Pehle right - second lap on right turn is timed. Then left turn - fourth lap on left is timed. must come to a full stop within 25m after crossing the timekeeping line) come up with ways we can complete skidpad \u2014 [P0] @Ayush Rohilla @DEs \u2705 Note assuming the map is placed as per the diagram: perc: mono / best pipeline (as bohut saare cones ek saath, time le skta hai to compute) slam: ekf localization to be figured out @Shreyash Gupta \u2014 hai ek library with feature map option\u2026 ppc: we know the boundaries either way, so we\u2019ll know what middle path to follow perc: same slam: try with mrpt, range ~15m; can we alter the meas coming in so that cones given by perception always lie on boundary? sounds fishy. assuming the map isn\u2019t placed as per the diagram (but boundaries same): ppc: same next to-dos: make ppc code for this, same in both cases (try with/without error in car state) @ajinkya try with mrpt, cones location unknown @Shreyash Gupta make slam/localization code ready, & try with known cone positions @arnav Perception specific able to run from a launch file (fix path error) @Yash Rampuria \u2014 [P0] (blocking!) \u274c researching on how to: @Yash Rampuria \u2014 [P0] \u274c improve range in stereo/mono pipeline? improve latency in mono pipelines? using nueral network: @tangri \u2014 [P0] \u274c lidar pipeline: @nakul \u2014 [P1] \u274c Find u v of a cone centre approximately and using step 3 ka result, find corresponding depth: ~2-3 days \u2705 nan values error \u2192 last year code lookup; ~2-3 days (nakul ka code, not continuing) talk to @namitha? currently working on prev DEs ke code, fixing many errors\u2026 (not sure if transformation matrix is right) working on: we\u2019ll take depth from lidar + use cam for classification (not only lidar pipeline\u2026) yolo retraining: @abhimanyu \u2014 [P1] sensors (zed / lidar) launch nahi hote everytime, bt dete hain \u274c blue/yellow cones ko bg classify kar rha hai - esp for far cones same cone pe do bounding boxes \u2192 non-max suppression threshold change (v5 pe hat gye the) \u2705 will try yoloV8: more stable \u2192 thode better results \u2192 have to train on better resolutions on colab \u2705 get help from @amit-sethi on training will need more training with colab sift on gpu @rajit \u2014 [P0] (blocking!) \u2705 zed, cuda sab installed! Note \u2753 Mono giving different sizes of bounding box for one side \u2192 some bias in depth \u2192 perception + slam: deviating from straight. @Yash Rampuria what are we doing about this?? \u2014 retraining mono + sensors (zed / lidar) launch nahi hote everytime, bt dete hain Slam specific root cause for data association issue (in fsds, with fake meas) \u2014 [P0] @Shreyash Gupta \u274c update/correct full code according to a single ref by sunday (blocking!) (~1din aur) do a very structured root cause analysis graphslam @Shreyash Gupta @rohan \u2014 [P1] figure out g2o & graphslam implementation (g2o, \u2026?) \u2705 understanding the example slam2d what is input & output format???? start writting some code for\u2026 (what should we aim for initially?) \u274c include hone mein BT lelarge waala paper padh le - compares ekf slam vs graphslam \u2705 EKF SLAM vs GraphSLAM ~~porting fastslam \u2192 carmaker @Shreyash Gupta @arnav \u2014 [P1]~~ connecting perc to slam @rajit \u2014 [P1] \u274c better velocity estimation / odometry estimation method @amna \u2014 [P1] \u2705 rnn *1layer vs 2layer, *mkf with sensors: mkf is best, rnn 1layer is similar rnn 1 layer: motor encoder, two imu (?) , gnss mkf.. ke sensors? struggling to get implementation details PPC specific get & understand psuedo-transient model from @chandu @Deep Boliya \u274c plan on delaunay triangulation @deep \u2705 implementing @shubham Complete stanley implementation @ajinkya @ayush \u274c ~2 days code likh liya hai for stanley, but error hai, starting mein right le rha hai ~~get fsds working with ros bridge~~ and implement Pure pursuit @shubham \u274c ~~get fsds working, core dumped @ayush (blocking!) ~~ Note \ud83d\udccc JDEs trying to implement ppc without looking into code, interpolating + stanley controller + vel profile / pure-pursuit ~ 3-4 more days. They\u2019re coming with some new ideas to implement. Sys-int specific able to run iitbdv repo, with docker, on fsds rosbag (mono, mrpt, middle/raceline + accel) @bhaskar (blocking!) \u274c figuring out gui in ros docker \u2705 figure out how to sync docker files/images?? - does whole 14gb docker image get \u2192 only parts, not whole \u2705 kaburnates\u2026 managing docker files? (for multiple docker) \u2705 on rosbag github actions \u2192 on push check if everything is building correctly explore CAN in carmaker @MG @vishwam \u274c ya to transfer deep \u2192 vishwam, aur liscense need ask @Ayush Rohilla exploring: how to make our own simulator @MG \u274c Note \u2753 carmaker: cone ke white stripes nahi hone chahiye, road ke white stripes se interfere (have cone models with black stripes) @Mohak Vyas. Will we be able to do this? \u2014 ask on forum Jetson \u2014 [P0] \u274c not booting up, try reinstalling / force recovery mode ubuntu @Mohak Vyas @vishwam (blocking!) Team wiki completion \u2014 [P2] \u274c Perception: incorporate the feedbacks, more pages? @Yash Rampuria SLAM: complete MRPT page @Shreyash Gupta Sys int: incorporate the feedbacks, more pages (simulatation, bot) @Mohak Vyas @MG Ideation on Trainee modules - [P2] \u274c Recruitment might start late. Need a different/structured recruitment + trainee module plan so that: reach more freshers, when we\u2019re starting recruitment late? min effort by team (a lot of time/effort goes for debugging errors / installing in the modules) structured week-by-week content with assignments documented on docs / github meeting with trainees one time a week? a good efficient outcome (we gave 4 months, but they still some have installation issues + need to more training to be able to contribute to their subsystem). should we spend less time in modules, and make JDEs faster so they\u2019ve more time to learn their subsytems? how to improve SLAM module? - no first pref till now \u2639\ufe0f React \ud83c\udfce\ufe0f to the whatsapp msg, if you\u2019ve carefully read & acknowledged the priorities for this week.","title":"Oct 2 - Oct 9 [7/30 = 23.33%]"},{"location":"updates/#sept-26-oct-1-1227-44","text":"Sim dev setup in Carmaker @Mohak Vyas \u274c github repo setup \u2014 [P0 !!] should be able to launch carmaker easily change topic names to common topic names chosen launch file for acceleration able to get ground truth info (cones/car location, speed, \u2026) \u2014 [P0] acceleration map ready \u2014 [P0] Acceleration in carmaker @Deep Boliya 0.3m from starting line, 75m track length, 3m wide, 100m stopping length list alternative ways to complete acceleration \u2014 [P0] \u2705 seeing first few cones & interpolating to get boundary paths to stay within boundary, we\u2019ll need to know our location \u2192 use odometry initial cones might not be accurate enough \u2192 lines might not be very straight [ ] plot in rviz to test this using Lidar only orientation based on assumption that car is staged centered + we can get accurate yaw for a while from imu bearing method (fix the stopping position, Thu night) \u2192 carmaker \u2014 [P0] \u2705 what are possible wrong outcomes, with this implementation? on ads-dv will need to aim for an ideal speed to follow, such that pts max + are able to stop safely within 100m (depends on the stopping potential) Note \ud83d\ude80 FSDS mein: speed 4ms se zyaada nhi off track jaate hi gone case can we use orientation of car to further improve this?? using total distance travelled as stopping logic\u2026 assuming distance from encoder data to be pretty acurate (as per deep\u2019s experience with ADS-DV), if ads-dv isn\u2019t giving accurate distance tune it there to go more than 75m or less than 75m as req\u2026 further to dos: start mein teda krke chala ke dekho\u2026 AS_FINISH logic, and successfully return \u2018AS_FINSIH\u2019 on terminal - can be done when we port \u2192 Carmaker tuning the pid improving controller \u2192 differential one clamp steering (not do too much steering at any time) (ya to extreme case nahi aayega ya recover nahi hoga) weighted sum with orientation (not much weight) if off track: yellow/blue identify karke make a turn (if speed is enough, we might not have enough time to see all yellow & deicide to make a turn) start impelementing \u2018alternate ways\u2019 \u2014 [P1] \u274c Perception specific able to run from a launch file (fix path error) @Yash Rampuria \u2014 [P0] \u274c researching on how to: @Yash Rampuria \u2014 [P1] \u274c improve latency in mono pipelines? improve range in stereo/mono pipeline? lidar pipeline: @nakul @abhimanyu \u2014 [P1] Put the transformation matrix in a variable as a multiplication of 3 4 different transformations (exteinsic intrinsic etc) \u2705 Learn how to read pcd data \u2705 Pcd has data in the format (x y z I) and u need to convert it to (u v depth) \u2705 Find u v of a cone centre approximately and using step 3 ka result, find corresponding depth - ~ 2-3 days \u274c sift on gpu @rajit - driver error \u274c Note \u2753 Mono giving different sizes of bounding box for one side \u2192 some bias in depth \u2192 perception + slam: deviating from straight. @Yash Rampuria what are we doing about this?? Slam specific root cause for data association issue (in fsds, with fake meas) \u2014 [P0] @Shreyash Gupta \u274c graphslam: come up with a plan @Shreyash Gupta @rohan \u2014 [P1] collect resources \u2705 get overview of the algo \u2705 examples on how it can be implemented (g2o, \u2026?) \u274c porting fastslam \u2192 carmaker @Shreyash Gupta @arnav\u2014 [P1] \u274c better velocity estimation method @amna \u2014 [P1] \u274c ~~porting mrpt \u2192 carmaker??? (ho rakha hai)~~ PPC specific @Deep Boliya to add jde tasks for this week \u274c Note \ud83d\udccc JDEs trying to implement ppc without looking into code, interpolating + stanley controller + vel profile / pure-pursuit ~ 3-4 more days. Through this they\u2019re coming with some new ideas to implement. Sys-int specific ros2 karna hai ki nahi? (~1-2 din mein decide) \u2014 [P1] @Mohak Vyas \u2705 nahi for now: faaltu bt nhi lena hai / ros2 has a better way to send msgs than ros1 (less delays due to truely parallel architecture) / ros1 noetic eol in 2025, have two years atleast / we\u2019re all familiar with ros1, will take some to get used to ros2 as well docker: plan for integrating (~1-2 din) \u2014 [P0] @MG @jdes \u2705 what should the final output be like? (what all will it \u2018contain\u2019? system requirements, probably require nvidia graphic cards?) things the docker should contain https://docs.google.com/document/d/1ojJ-bONWIKGVy3xhxL1UiQXZqVMYcOj-czewkg0QXAo/edit Note \u2753 carmaker: cone ke white stripes nahi hone chahiye, road ke white stripes se interfere (have cone models with black stripes) @Mohak Vyas. Will we be able to do this? Jetson \u2014 [P0] not booting up, try reinstalling / force recovery mode ubuntu @Mohak Vyas \u274c reach out to nvidia/help center/\u2026 @Ayush Rohilla \u2705 reaching out through forums - suggesting same, that we should reflash our board with sdkmanager from another x86 host https://forums.developer.nvidia.com/t/jetson-agx-orin-not-booting-up/267798 trying force recovery mode - https://forums.developer.nvidia.com/t/agx-orin-not-booting/258038 Team wiki completion \u2014 [P1] Perception: incorporate the feedbacks, more pages? @Yash Rampuria \u274c SLAM: complete MRPT page @Shreyash Gupta \u274c Sys int: incorporate the feedbacks, more pages (simulatation, bot) @Mohak Vyas @MG \u274c Overview: home, goal & vision 2024, ~~compi 101~~, ~~culture?~~ @Ayush Rohilla \u2705 Local to web, using github hosting, (any method to keep it private!??) @Ayush Rohilla \u2705 github host from org - not possible, with a personal account, public repo - host possible need to search for alternate tools for free private github pages -- static.app/sites fast enough (https://lime-otter.static.domains/) Doubts whats stopping us to use Windows instead of linux (LOL had existential crisis for a min)? \u2014 jetson mein linux hota hai","title":"Sept 26 - Oct 1 [12/27 = 44%]"},{"location":"updates/#sept-13-sept-25","text":"Midsem break","title":"Sept 13 - Sept 25"},{"location":"updates/#sept-4-sept-12-1020-50","text":"Metric targets for perception/slam/ppc to reach for a successfull integration @DEs @Ayush Rohilla \u2014 [P0] Perception: accuracy, range, outlier%, latency \u2705 currently we\u2019re at - range<10m (less than two pairs of cones visible), latency bad for stereo with sift, avg error ~3.38% for mono Range: <10m \u2192 15+m Latency: 2-3sec / 100ms \u2192 50ms (20hz) Avg error: ?? SLAM: mean squared error, cone count, matching ratio, error threshold, latency of output to ppc \u274c currently we\u2019re at - min range that works is~20m with custom_meas of super accuracy, at about ~2m/s max velocity \u2014 nahi to it\u2019s not able to complete the whole lap were getting mean squared error of ~0.01 m^2, correct cone count for a lap (didn\u2019t calculate matching ratio / error threshold yet), latency ~100hz with update from meas ~20hz (noisy fake_meas ke saath try\u2026.) why multiple freq in IMU? extra cones being identified discuss with @Shreyash Gupta PPC: time taken in each type of event (also our north star metric), cones hit, max vel/accln raceline: 32sec, firstlap: ? (range se input leke) \u2705 cones hit: 0, max vel: ?, max accel: ? accln: ~6-7 sec, skidpad: ~30sec, trackdrive: ~1min (+-20sec), fastlap: fsai mein to slow slow hi (check fsg timings) can PPC take & use gridmap??? (mainly frequency pe hi depend karega output, given error itna hai ki it can complete event) Tentative targets in simulations Accln: 5sec Skidpad: 20sec Autocross: 45sec Trackdrive: 35sec SLAM - which algorithms to prioritize on? (tough question!) @Shreyash Gupta @Ayush Rohilla \u2014 [P0] \u2705 EKF meas mein use fake meas FSDS\u2026 (can debug) \u2014 root cause??? fastSLAM \u2014 port to FSDS (from fssim) graphslam \u2014 what is g2o / how to implement? mrpt \u2014 localization with range bearing (if possible) Which simulator to continue on? Carmaker (global cones position/route coordinates? & IMU sensor add?) @Mohak Vyas \u2014 [P0] \u2705 FSDS (depthmap isn\u2019t correct!) @Mohak Vyas @Yash Rampuria \u2014 [P1] \u274c FSSIM (why did we discontinue this + current state?) @Ayush Rohilla \u2014 [P1] \u274c Steps to create our own simulator @Mohak Vyas \u2014 [P2] \u274c Different strategies to complete Accln Other ways to do accln?? \u2014 [P0] \u274c Perc + PPC (with no slam) finish implementing @Yash Rampuria @Deep Boliya \u2014 [P1] \u2705 Jetson status\u2026 @Deep Boliya @Mohak Vyas @Ayush Rohilla \u2014 [P0] \u2705 send to Nvidia if broken / we can\u2019t fix it :( not booting up, try reinstalling os +have reach out to nvidia JDE KTs (knowledge transfer) @DEs @JDEs \u2014 [P0] \u2705 we want all JDEs to be able to contribute to the team asap!! have started giving them real tasks as well\u2026 Team wiki completion \u2014 [P1] Perception: incorporate the feedbacks, more pages? @Yash Rampuria \u274c SLAM: complete MRPT page @Shreyash Gupta \u274c PPC: incorporate the feedbacks, add vehicle dynamics/controls/ads-dv page @Deep Boliya \u2705 Sys int: incorporate the feedbacks, more pages (simulatation, bot) @Mohak Vyas @MG \u274c Overview: home, goal & vision 2024, compi 101, culture? @Ayush Rohilla \u274c Local to web, using github hosting @Ayush Rohilla \u274c Sys architecture + repo structure @DEs @Ayush Rohilla \u2014 [P1] \u2705 Rulebook prep for quiz on Sat @DEs @JDEs \u2014 [P1] \u2705","title":"Sept 4 - Sept 12 [10/20 = 50%]"},{"location":"controls/controls/","text":"Controls This sections includes all the nitty-gritty of the algorithms involved in controls and the results obtained Acceleration / Braking We need to generate smooth a acceleration and braking actuation signals to follow the velocity profile generated. We imploy a PID controller to do so. PID control Our controller takes in the error as the signed difference between the current speed and desired speed. The desired speed is the speed at the closet waypoint given by velocity profile. Put the control loop here Problems Faced Tuning our parameters for simulators like fsds is hard, let alone tuning the pararmeters for the actual which we do not even have. Put the control loop here More so on simulators, we don't face the inefficiencies of real life and hence tuning the Controller is even harder. After resolving issues Here are the best results from the simulators testing, where only only PPC is being tested Wrong implementation of the PID controller Velocity Profile Generation The optimal velocity at each point is calculated by taking into account the max frictional force available. The centripetal force and the lateral acceleration provided by friction. So intuitively due to higher centripetal force at turns compared to a stright at the same velocity, we have lesser friction for acceleration and deceleration. So after Steering Pure Pursuit algorithm A PID controller was used to control the accelerator and braking measurement. This controller initially being tuned wasn't actually a PID control because it took the previous output of the control loop as a parameter rather than the previous error while trying to follow a velocity profile. And a differentiator on the output prevented the accelerator from clipping keeping the cra slow and hence even after a wrong implementation of the controller, the car stayed on track. Steering control Explain any shortcomings/issues with the algorithm and/or our implementation of it. Challenges faced Explain any challenges we faced while implementing the algorithm. What could be done next? Delaunay triangulation for path planning in the first lap Stanley controller for steering Algorithms explored till now Path Planning Midpoint trajecotory Raceline trajectory Controls PID control for braking/accelerating Pure pursuit algorithm for steering written by Deep Boliya","title":"Controls"},{"location":"controls/controls/#controls","text":"This sections includes all the nitty-gritty of the algorithms involved in controls and the results obtained","title":"Controls"},{"location":"controls/controls/#acceleration-braking","text":"We need to generate smooth a acceleration and braking actuation signals to follow the velocity profile generated. We imploy a PID controller to do so.","title":"Acceleration / Braking"},{"location":"controls/controls/#pid-control","text":"Our controller takes in the error as the signed difference between the current speed and desired speed. The desired speed is the speed at the closet waypoint given by velocity profile. Put the control loop here","title":"PID control"},{"location":"controls/controls/#problems-faced","text":"Tuning our parameters for simulators like fsds is hard, let alone tuning the pararmeters for the actual which we do not even have. Put the control loop here More so on simulators, we don't face the inefficiencies of real life and hence tuning the Controller is even harder.","title":"Problems Faced"},{"location":"controls/controls/#after-resolving-issues","text":"Here are the best results from the simulators testing, where only only PPC is being tested Wrong implementation of the PID controller","title":"After resolving issues"},{"location":"controls/controls/#velocity-profile-generation","text":"The optimal velocity at each point is calculated by taking into account the max frictional force available. The centripetal force and the lateral acceleration provided by friction. So intuitively due to higher centripetal force at turns compared to a stright at the same velocity, we have lesser friction for acceleration and deceleration. So after","title":"Velocity Profile Generation"},{"location":"controls/controls/#steering","text":"","title":"Steering"},{"location":"controls/controls/#pure-pursuit-algorithm","text":"A PID controller was used to control the accelerator and braking measurement. This controller initially being tuned wasn't actually a PID control because it took the previous output of the control loop as a parameter rather than the previous error while trying to follow a velocity profile. And a differentiator on the output prevented the accelerator from clipping keeping the cra slow and hence even after a wrong implementation of the controller, the car stayed on track.","title":"Pure Pursuit algorithm"},{"location":"controls/controls/#steering-control","text":"Explain any shortcomings/issues with the algorithm and/or our implementation of it.","title":"Steering control"},{"location":"controls/controls/#challenges-faced","text":"Explain any challenges we faced while implementing the algorithm.","title":"Challenges faced"},{"location":"controls/controls/#what-could-be-done-next","text":"Delaunay triangulation for path planning in the first lap Stanley controller for steering","title":"What could be done next?"},{"location":"controls/controls/#algorithms-explored-till-now","text":"","title":"Algorithms explored till now"},{"location":"controls/controls/#path-planning","text":"Midpoint trajecotory Raceline trajectory","title":"Path Planning"},{"location":"controls/controls/#controls_1","text":"PID control for braking/accelerating Pure pursuit algorithm for steering written by Deep Boliya","title":"Controls"},{"location":"controls/overview/","text":"Overview Our aim: Get an optimal track to be followed Give throttle/brakes/steering command to the car to follow that path Algorithms Explored till now :- For Steering: Pure Pursuit Controller Steering proportional Cross track error For Throttle/Brakes: PID control What we did in 2022-23 Firstly, we mainly worked on the improving only our PPC algorithms by using entire map of cones and the co-ordinates of car given by simulator directly. We tried to obtain the raceline via different methods. The pipelines integration was done in a step by step manner, where-in SLAM+PPC was integrated via fake perception measurements on fsds simulator. We also developed a bot to integrate and test our pipeline. Path Planning During planning we try to obtain the waypoint using the global coordiantes of the cones receieved by SLAM. In the first lap, mid-point trajectory is followed. We expect to follow the raceline after the first lap as we have the entire map after the first lap Controls Throttle / Brakes :- A PID controller was used to control the accelerator and braking measurement. Steering control :- A pure pursuit controller with varying look ahead vector was implemented to calculate our steering angle What wasn't going well The throttle/brakes controller was not actually a PID, the differential term was taken to be the rate of change of the velocity which is theortically not correct but the car still loosely followed the velocity profile. Path planning algorithm only worked for entire blue and yellow cones array, and also the closest cones were already matched, i.e. the cones at same index in both the arrays had the same index There was no algorithm in place for the first lap of the track when the environment is not known Raceline generation takes time. We can't wait after the first lap for the compute to generate the raceline. On the fsds simulator, the car always used to hit a cone which might be because of wrong:- velocity profile generation throttle/brake controller written by Deep Boliya","title":"Overview"},{"location":"controls/overview/#overview","text":"Our aim: Get an optimal track to be followed Give throttle/brakes/steering command to the car to follow that path Algorithms Explored till now :- For Steering: Pure Pursuit Controller Steering proportional Cross track error For Throttle/Brakes: PID control","title":"Overview"},{"location":"controls/overview/#what-we-did-in-2022-23","text":"Firstly, we mainly worked on the improving only our PPC algorithms by using entire map of cones and the co-ordinates of car given by simulator directly. We tried to obtain the raceline via different methods. The pipelines integration was done in a step by step manner, where-in SLAM+PPC was integrated via fake perception measurements on fsds simulator. We also developed a bot to integrate and test our pipeline.","title":"What we did in 2022-23"},{"location":"controls/overview/#path-planning","text":"During planning we try to obtain the waypoint using the global coordiantes of the cones receieved by SLAM. In the first lap, mid-point trajectory is followed. We expect to follow the raceline after the first lap as we have the entire map after the first lap","title":"Path Planning"},{"location":"controls/overview/#controls","text":"Throttle / Brakes :- A PID controller was used to control the accelerator and braking measurement. Steering control :- A pure pursuit controller with varying look ahead vector was implemented to calculate our steering angle","title":"Controls"},{"location":"controls/overview/#what-wasnt-going-well","text":"The throttle/brakes controller was not actually a PID, the differential term was taken to be the rate of change of the velocity which is theortically not correct but the car still loosely followed the velocity profile. Path planning algorithm only worked for entire blue and yellow cones array, and also the closest cones were already matched, i.e. the cones at same index in both the arrays had the same index There was no algorithm in place for the first lap of the track when the environment is not known Raceline generation takes time. We can't wait after the first lap for the compute to generate the raceline. On the fsds simulator, the car always used to hit a cone which might be because of wrong:- velocity profile generation throttle/brake controller written by Deep Boliya","title":"What wasn't going well"},{"location":"controls/planning/","text":"Overview What we did in 2022-23 Firstly, we mainly worked on the improving only our PPC algorithms by using entire map of cones and the co-ordinates of car given by simulator directly. We tried to obtain the raceline via different methods. The pipelines integration was done in a step by step manner, where-in SLAM+PPC was integrated via fake perception measurements on fsds simulator. We also developed a bot to integrate and test our pipeline. Path Planning Using the entire array of blue and yellow cones given by fsds, the midpoint of cones was taken where the the closest blue cone and the yellow cone had the same index and the mid-point trajectory was generated by joining those midpoints by bezier curves. To generated the raceline, the tracked was divided into sections where a way point lied whose location was goverened by a parameter alpha. After this two things could have been done: Use the lap time as the objective function itself Use the sum of curvatures at discrete points on the track Complexity of method 1 was much higher because for a given set of parameters (alphas), we had to interpolate, generate corresponding velocity profile, get distances between all the waypoints, the divide each distance by the velocity on that points. Hence method 2 was used, which gave us very good and satisfactory results. First lap How we tried to resolve it This was resolved by matching the yellow cones with the closest blue cone out of all the blue cones. And if the distance between closest blue cones was more than a certain threshold, no matching was done. The velocity profile generated wasn't wrong theoritically. After appling What wasn't going well The array receieved by fsds has same index, so matching blue and yellow cones was not a problem. In real scenerio, this will not be the case because cones much further ahead can be encountered by pereception and hence this method will not work. The velocity profile generated was not correct, because while running only ppc code on the training map, the car always used to hit some cones at the very end of the lap How we tried to resolve it This was resolved by matching the yellow cones with the closest blue cone out of all the blue cones. And if the distance between closest blue cones was more than a certain threshold, no matching was done. The velocity profile generated wasn't wrong theoritically. After appling Controls Acceleration / Braking A PID controller was used to control the accelerator and braking measurement. Steering control A pure pursuit controller with varying look ahead vector was implemented to calculate our steering angle What could be done next? Delaunay triangulation for path planning in the first lap Stanley controller for steering written by Deep Boliya","title":"Path Planning"},{"location":"controls/planning/#overview","text":"","title":"Overview"},{"location":"controls/planning/#what-we-did-in-2022-23","text":"Firstly, we mainly worked on the improving only our PPC algorithms by using entire map of cones and the co-ordinates of car given by simulator directly. We tried to obtain the raceline via different methods. The pipelines integration was done in a step by step manner, where-in SLAM+PPC was integrated via fake perception measurements on fsds simulator. We also developed a bot to integrate and test our pipeline.","title":"What we did in 2022-23"},{"location":"controls/planning/#path-planning","text":"Using the entire array of blue and yellow cones given by fsds, the midpoint of cones was taken where the the closest blue cone and the yellow cone had the same index and the mid-point trajectory was generated by joining those midpoints by bezier curves. To generated the raceline, the tracked was divided into sections where a way point lied whose location was goverened by a parameter alpha. After this two things could have been done: Use the lap time as the objective function itself Use the sum of curvatures at discrete points on the track Complexity of method 1 was much higher because for a given set of parameters (alphas), we had to interpolate, generate corresponding velocity profile, get distances between all the waypoints, the divide each distance by the velocity on that points. Hence method 2 was used, which gave us very good and satisfactory results.","title":"Path Planning"},{"location":"controls/planning/#first-lap","text":"","title":"First lap"},{"location":"controls/planning/#how-we-tried-to-resolve-it","text":"This was resolved by matching the yellow cones with the closest blue cone out of all the blue cones. And if the distance between closest blue cones was more than a certain threshold, no matching was done. The velocity profile generated wasn't wrong theoritically. After appling","title":"How we tried to resolve it"},{"location":"controls/planning/#what-wasnt-going-well","text":"The array receieved by fsds has same index, so matching blue and yellow cones was not a problem. In real scenerio, this will not be the case because cones much further ahead can be encountered by pereception and hence this method will not work. The velocity profile generated was not correct, because while running only ppc code on the training map, the car always used to hit some cones at the very end of the lap","title":"What wasn't going well"},{"location":"controls/planning/#how-we-tried-to-resolve-it_1","text":"This was resolved by matching the yellow cones with the closest blue cone out of all the blue cones. And if the distance between closest blue cones was more than a certain threshold, no matching was done. The velocity profile generated wasn't wrong theoritically. After appling","title":"How we tried to resolve it"},{"location":"controls/planning/#controls","text":"","title":"Controls"},{"location":"controls/planning/#acceleration-braking","text":"A PID controller was used to control the accelerator and braking measurement.","title":"Acceleration / Braking"},{"location":"controls/planning/#steering-control","text":"A pure pursuit controller with varying look ahead vector was implemented to calculate our steering angle","title":"Steering control"},{"location":"controls/planning/#what-could-be-done-next","text":"Delaunay triangulation for path planning in the first lap Stanley controller for steering written by Deep Boliya","title":"What could be done next?"},{"location":"estimation/ekf_slam/","text":"EKF SLAM Since the competition track would contain only cones, a feature/landmark based mapping is sufficient. Also, as the total number of features (or cones) will not be very high, EKF SLAM (being extensively researched) has shown that with a slightly modified architecture, it is real-time capable. Although not the most efficient algorithm (especially for complex scenarios), it has proved to be a good starting point for us. The algorithm can be divided in 2 steps: 1. Motion Update 2. Measurement Update Motion Update We have used a simple motion model so that it updates the state frequently which is essential for real-time capabilities, with its output depending on the frequency of the odometry data (which is ~100 Hz). Due to inconsistency in input frequencies (because of reasons like synchronizing from multiple sensors and performance issues) a real-time sync \u0394t is implemented, calculated dynamically by the time taken to perform the motion update again. This results in slightly better estimations from the motion model. Measurement Update The measurement update step is computationally heavy as it checks for the matches between new measurements and the existing map which may lead to correction of the entire map and position of the car, i.e. complete state and covariance matrix have to be adjusted. The time taken largely depends on the square of the number of landmarks present on the map (or simply map size). The measurements of the observed cones for the measurement update, if taken from the camera, have a larger scope for error compared with lidar depths. Since the ICNN (Individually Compatible Nearest Neighbour) approach for data association is very sensitive to the increase in vehicle and sensor error, spurious pairings can easily be formed and will never be reconsidered. Hence, the JCBB (Joint Compatibility Branch and Bound) algorithm for data association was selected. Experiments have shown that JCBB is not only more robust than Nearest Neighbour, but also feasible in terms of computational cost. Because of the unavoidable errors in the sensors, some false positive landmarks can be recorded, which hamper the Path Planning algorithm and the data association step of the measurement update. This can be eliminated by keeping a threshold value for the number of times a landmark is observed. If the cone is under the threshold, it's removed from the map. Serial Vs Parallel Structre Initially, we tried to use the serial structure in which the motion update step is performed just after the measurement step is finished. This will not be real-time capable because the next motion update cannot begin until the measurement update is finished as measurement update takes a large time to finish. Also this presented a potential risk to the path planning algorithm, as an outdated car position could have serious consequences. The answer to this problem is the parallelization of the motion and measurement update steps. The updated pose was adjusted for the difference in the initial pose to account for the prediction made since the measurement was received. This allows the algorithm to keep predicting the position estimated while performing the measurement step in the background. This solves all of the problems mentioned above: the data is processed at different frequencies so there is always a short-term pose available for the subsequent module (Path Planning) to work with, and measurement update can take the required time until it is completed or until a new measurement from sensors is available. Loop Closure After one lap of the track, a static map is created and further observations will not increase the quality of the map significantly. This detection of the completion of a lap is called Loop Closure. This also increases the overall accuracy of all landmarks, as when the car is about to complete a loop, it re-observes some of the old landmarks(error in the location of these landmarks is very less). Incorrect loop closure results in catastrophic failure of SLAM and needs to be avoided to create a reliable system. Loop closure is identified using three conditions: It should detect orange cones (which mark starting and stopping positions). The estimated position of the car should be very similar to that of the initial position(\u00b11m). The car's current heading has to be similar to the initial heading(\u00b15\u00b0). After detecting loop closure, the car shifts from SLAM to Localization mode, where only the car's position is adjusted based on the cones detected. What went well? We were able to run motion update and get pretty good results on everything FSDS simulator, Carmaker, Bot, and ADS-DV. Loop closure was detected accurately on the FSDS simulator. What didnt went well? We werent able to run measurement update on the FSDS . It could be due to the erroneous reading(wrong depthmap) provided by the simulator or an error in data association part of the algorithm we wrote. As measurement update didnt work, there was no point in trying in the parallel structure of motion update and measurment. What we did? we chose to utilize available libraries and packages, which allowed for faster experimentation but provided less flexibility. Despite this limitation, these libraries served as a foundation for improving the precision and accuracy of our results. What is the plan for future? Run measurement update on FSDS(using false perception reading), Carmaker and bot Make all the custom changes like other teams did(eg. keeping a threshold on number of times a landmark is seen before entering it in map) Implement parallel structure of motion and measurment update Implement Localisation part of the algorithm as well and check it on the simulators. On loop closure, implement conversion from SLAM to Localisation. written by Shreyash Gupta","title":"EKF SLAM"},{"location":"estimation/ekf_slam/#ekf-slam","text":"Since the competition track would contain only cones, a feature/landmark based mapping is sufficient. Also, as the total number of features (or cones) will not be very high, EKF SLAM (being extensively researched) has shown that with a slightly modified architecture, it is real-time capable. Although not the most efficient algorithm (especially for complex scenarios), it has proved to be a good starting point for us. The algorithm can be divided in 2 steps: 1. Motion Update 2. Measurement Update","title":"EKF SLAM"},{"location":"estimation/ekf_slam/#motion-update","text":"We have used a simple motion model so that it updates the state frequently which is essential for real-time capabilities, with its output depending on the frequency of the odometry data (which is ~100 Hz). Due to inconsistency in input frequencies (because of reasons like synchronizing from multiple sensors and performance issues) a real-time sync \u0394t is implemented, calculated dynamically by the time taken to perform the motion update again. This results in slightly better estimations from the motion model.","title":"Motion Update"},{"location":"estimation/ekf_slam/#measurement-update","text":"The measurement update step is computationally heavy as it checks for the matches between new measurements and the existing map which may lead to correction of the entire map and position of the car, i.e. complete state and covariance matrix have to be adjusted. The time taken largely depends on the square of the number of landmarks present on the map (or simply map size). The measurements of the observed cones for the measurement update, if taken from the camera, have a larger scope for error compared with lidar depths. Since the ICNN (Individually Compatible Nearest Neighbour) approach for data association is very sensitive to the increase in vehicle and sensor error, spurious pairings can easily be formed and will never be reconsidered. Hence, the JCBB (Joint Compatibility Branch and Bound) algorithm for data association was selected. Experiments have shown that JCBB is not only more robust than Nearest Neighbour, but also feasible in terms of computational cost. Because of the unavoidable errors in the sensors, some false positive landmarks can be recorded, which hamper the Path Planning algorithm and the data association step of the measurement update. This can be eliminated by keeping a threshold value for the number of times a landmark is observed. If the cone is under the threshold, it's removed from the map.","title":"Measurement Update"},{"location":"estimation/ekf_slam/#serial-vs-parallel-structre","text":"Initially, we tried to use the serial structure in which the motion update step is performed just after the measurement step is finished. This will not be real-time capable because the next motion update cannot begin until the measurement update is finished as measurement update takes a large time to finish. Also this presented a potential risk to the path planning algorithm, as an outdated car position could have serious consequences. The answer to this problem is the parallelization of the motion and measurement update steps. The updated pose was adjusted for the difference in the initial pose to account for the prediction made since the measurement was received. This allows the algorithm to keep predicting the position estimated while performing the measurement step in the background. This solves all of the problems mentioned above: the data is processed at different frequencies so there is always a short-term pose available for the subsequent module (Path Planning) to work with, and measurement update can take the required time until it is completed or until a new measurement from sensors is available.","title":"Serial Vs Parallel Structre"},{"location":"estimation/ekf_slam/#loop-closure","text":"After one lap of the track, a static map is created and further observations will not increase the quality of the map significantly. This detection of the completion of a lap is called Loop Closure. This also increases the overall accuracy of all landmarks, as when the car is about to complete a loop, it re-observes some of the old landmarks(error in the location of these landmarks is very less). Incorrect loop closure results in catastrophic failure of SLAM and needs to be avoided to create a reliable system. Loop closure is identified using three conditions: It should detect orange cones (which mark starting and stopping positions). The estimated position of the car should be very similar to that of the initial position(\u00b11m). The car's current heading has to be similar to the initial heading(\u00b15\u00b0). After detecting loop closure, the car shifts from SLAM to Localization mode, where only the car's position is adjusted based on the cones detected.","title":"Loop Closure"},{"location":"estimation/ekf_slam/#what-went-well","text":"We were able to run motion update and get pretty good results on everything FSDS simulator, Carmaker, Bot, and ADS-DV. Loop closure was detected accurately on the FSDS simulator.","title":"What went well?"},{"location":"estimation/ekf_slam/#what-didnt-went-well","text":"We werent able to run measurement update on the FSDS . It could be due to the erroneous reading(wrong depthmap) provided by the simulator or an error in data association part of the algorithm we wrote. As measurement update didnt work, there was no point in trying in the parallel structure of motion update and measurment.","title":"What didnt went well?"},{"location":"estimation/ekf_slam/#what-we-did","text":"we chose to utilize available libraries and packages, which allowed for faster experimentation but provided less flexibility. Despite this limitation, these libraries served as a foundation for improving the precision and accuracy of our results.","title":"What we did?"},{"location":"estimation/ekf_slam/#what-is-the-plan-for-future","text":"Run measurement update on FSDS(using false perception reading), Carmaker and bot Make all the custom changes like other teams did(eg. keeping a threshold on number of times a landmark is seen before entering it in map) Implement parallel structure of motion and measurment update Implement Localisation part of the algorithm as well and check it on the simulators. On loop closure, implement conversion from SLAM to Localisation. written by Shreyash Gupta","title":"What is the plan for future?"},{"location":"estimation/overview/","text":"Overview TO ADD: what we are planning to do this year... What we did in 2022-23 TL;DR: We initially planned to implement our own EKF SLAM algorithm in FSDS, but encountered problems with the data association step. Later found that the measurements coming in from the camera and lidar sensors were not correct. After spending several months trying to fix these problems, the team decided to implement SLAM libraries that are integrated with ROS - Cartographer & MRPT. Cartographer worked, but it produced a map that was not compatible with the PPC algorithm. MRPT worked better, but it only stored the positions of landmarks, not their colors. We fixed it using a \"jugaad\". Initial Plan We started to continue with the previous year's work, implementing the EKF SLAM algorithm. We were having some trouble implementing the measurement update (specifically, the data association part). This year the team made a decision to start working with the FSDS simulutor since it provides a realistic environment and not just some dummy sensors (were using FSSIM before). Fig: EKF SLAM (Motion update only) on FSSIM, before we started After setting up the simulator, we were able to run motion update with some effort, at the start of August. For trying to solve the data associtation problem, we saw many teams use an algorithm called JCBB (Joint Compatibility Branch and Bound) which is supposed to be more robust and faster than the Nearest Neighbour approach ( check this paper ). We referred to these codes for the implementation of JCBB. Since, different sources had different assumptions regarding the EKF algorithm, which meant different matrices with different sizes, it created a lot of confusion on which one to choose. We looked into the algorithm proofs, which helped in deciding that to some extent. But we still were getting very weird results, and were certainly not close to fixing the issue. Fig: Motion update (left) and Measurement update (right) on FSDS For detecting loop closure, we researched what other teams have implemented ( list sources ), and came out with the criterias that would have to match for a loop closure to be detected and hence switching from SLAM to Locaclization. This repository contains the most updated code for the EKF SLAM algorithm implemented. Check EKF SLAM for more details. What wasn't going well After a lot of trying, we found out that the measurements coming in with Camera and Lidar, with ROS bridge are not correct (they seem fine with the python client). Running camera also causes the simulator to have performence issues, see issue on github . By this time, we had already spent a lot of time on fixing measurement update issue (~3-4 months), and weren't confident enough to fix that before this season, which caused us to take a pause think about a different approach to implement SLAM. We explored a lot of libraries that provide SLAM implementations and found many are integrated with ROS itself (check out libraries for SLAM for details on slam libraries we explored). Library name Status Remarks rgbdslam_v2 Didn't start ros-kinetic, c++, boht realistic map orb_slam3 Halted tutorial of running it in FSDS, nvidia-docker requires nvidia gpu ov2_slam Didn't start stereo visual slam, ros melodic mrpt Works! many types of algorithms, has range-bearing EKF cartographer Works! LaserScan, occupancy grid gmapping Didn't start LaserScan, occupancy grid rtabmap Didn't start bunch of inputs/subscribers, RGBD gtsam Didn't start landmark based example given, ros integration? servo Didn't start used by AMZ team How we tried to resolve it We went ahead to first implement Cartographer ROS library as it had good documentation and was comparatively fairly recent too. With some effort, we were able to get it working with FSDS. We ran it with the bag recorded with PPC running controlling the car to follow middle line (following the tutorial here ). It worked but the results were not impressive, it was still mostly dependent on the odometry data we were providing, (motion update) and only did slight improvements to it. We also couldn't test it along with PPC, as Cartographer provides a occupancy grid type map, which is not what PPC expected (simple list/dict of cone position and color). Fig: Cartographer result, very little improvements (purple line: odometry estimation, green: output from Cartographer) There was only one ROS-integrated SLAM library, we found that could produce a simple map that PPC already worked with - MRPT . Implementing it was similar to Cartographer, so that helped. Since, still the issue of 'bad measurements' existed in the FSDS simulator, we had to work with fake measurements (returns the ground truth positions/color of cones relative to the car). With that its results were decent and we were able to get it running with PPC as well. One thing we missed - MRPT (ekf_slam_2d) only uses/stores the positions of landmarks (i.e. cones) and not their color, which again is a issue because PPC needs it to calculate the path to be followed. This was fixed as a 'jugaad' by using... (explain how we fixed it). What could be done next? Explain what we could do next to improve the results, and how we may move further. Algorithms explored till now List the algorithms/libraries we have explored till now, and give a breif description of each's implementation, the postives/negatives. EKF SLAM FastSLAM MRPT Cartographer written by Ayush Rohilla","title":"Overview"},{"location":"estimation/overview/#overview","text":"TO ADD: what we are planning to do this year...","title":"Overview"},{"location":"estimation/overview/#what-we-did-in-2022-23","text":"TL;DR: We initially planned to implement our own EKF SLAM algorithm in FSDS, but encountered problems with the data association step. Later found that the measurements coming in from the camera and lidar sensors were not correct. After spending several months trying to fix these problems, the team decided to implement SLAM libraries that are integrated with ROS - Cartographer & MRPT. Cartographer worked, but it produced a map that was not compatible with the PPC algorithm. MRPT worked better, but it only stored the positions of landmarks, not their colors. We fixed it using a \"jugaad\".","title":"What we did in 2022-23"},{"location":"estimation/overview/#initial-plan","text":"We started to continue with the previous year's work, implementing the EKF SLAM algorithm. We were having some trouble implementing the measurement update (specifically, the data association part). This year the team made a decision to start working with the FSDS simulutor since it provides a realistic environment and not just some dummy sensors (were using FSSIM before). Fig: EKF SLAM (Motion update only) on FSSIM, before we started After setting up the simulator, we were able to run motion update with some effort, at the start of August. For trying to solve the data associtation problem, we saw many teams use an algorithm called JCBB (Joint Compatibility Branch and Bound) which is supposed to be more robust and faster than the Nearest Neighbour approach ( check this paper ). We referred to these codes for the implementation of JCBB. Since, different sources had different assumptions regarding the EKF algorithm, which meant different matrices with different sizes, it created a lot of confusion on which one to choose. We looked into the algorithm proofs, which helped in deciding that to some extent. But we still were getting very weird results, and were certainly not close to fixing the issue. Fig: Motion update (left) and Measurement update (right) on FSDS For detecting loop closure, we researched what other teams have implemented ( list sources ), and came out with the criterias that would have to match for a loop closure to be detected and hence switching from SLAM to Locaclization. This repository contains the most updated code for the EKF SLAM algorithm implemented. Check EKF SLAM for more details.","title":"Initial Plan"},{"location":"estimation/overview/#what-wasnt-going-well","text":"After a lot of trying, we found out that the measurements coming in with Camera and Lidar, with ROS bridge are not correct (they seem fine with the python client). Running camera also causes the simulator to have performence issues, see issue on github . By this time, we had already spent a lot of time on fixing measurement update issue (~3-4 months), and weren't confident enough to fix that before this season, which caused us to take a pause think about a different approach to implement SLAM. We explored a lot of libraries that provide SLAM implementations and found many are integrated with ROS itself (check out libraries for SLAM for details on slam libraries we explored). Library name Status Remarks rgbdslam_v2 Didn't start ros-kinetic, c++, boht realistic map orb_slam3 Halted tutorial of running it in FSDS, nvidia-docker requires nvidia gpu ov2_slam Didn't start stereo visual slam, ros melodic mrpt Works! many types of algorithms, has range-bearing EKF cartographer Works! LaserScan, occupancy grid gmapping Didn't start LaserScan, occupancy grid rtabmap Didn't start bunch of inputs/subscribers, RGBD gtsam Didn't start landmark based example given, ros integration? servo Didn't start used by AMZ team","title":"What wasn't going well"},{"location":"estimation/overview/#how-we-tried-to-resolve-it","text":"We went ahead to first implement Cartographer ROS library as it had good documentation and was comparatively fairly recent too. With some effort, we were able to get it working with FSDS. We ran it with the bag recorded with PPC running controlling the car to follow middle line (following the tutorial here ). It worked but the results were not impressive, it was still mostly dependent on the odometry data we were providing, (motion update) and only did slight improvements to it. We also couldn't test it along with PPC, as Cartographer provides a occupancy grid type map, which is not what PPC expected (simple list/dict of cone position and color). Fig: Cartographer result, very little improvements (purple line: odometry estimation, green: output from Cartographer) There was only one ROS-integrated SLAM library, we found that could produce a simple map that PPC already worked with - MRPT . Implementing it was similar to Cartographer, so that helped. Since, still the issue of 'bad measurements' existed in the FSDS simulator, we had to work with fake measurements (returns the ground truth positions/color of cones relative to the car). With that its results were decent and we were able to get it running with PPC as well. One thing we missed - MRPT (ekf_slam_2d) only uses/stores the positions of landmarks (i.e. cones) and not their color, which again is a issue because PPC needs it to calculate the path to be followed. This was fixed as a 'jugaad' by using... (explain how we fixed it).","title":"How we tried to resolve it"},{"location":"estimation/overview/#what-could-be-done-next","text":"Explain what we could do next to improve the results, and how we may move further.","title":"What could be done next?"},{"location":"estimation/overview/#algorithms-explored-till-now","text":"List the algorithms/libraries we have explored till now, and give a breif description of each's implementation, the postives/negatives. EKF SLAM FastSLAM MRPT Cartographer written by Ayush Rohilla","title":"Algorithms explored till now"},{"location":"perception/overview/","text":"Overview Takes in data from LiDAR and ZED2i stereo cams (have to choose between taking from 2 stereocams or 1 stereocam), find class, depth and bearing of cone and send this to SLAM Pipelines for depth estimation: Stereo (Running) Mono using PnP (Running, not very good) Mono using BB height + stereo for edge cases (Running) Lidar only (To be developed) Lidar Mono fusion (Running, although very bad) Accuracy: Mono BB height > Stereo > Mono PnP >>>> Lidar fusion Latency: Mono BB height < Mono PnP < Stereo (Lidar unkown) Major issues: SIFT latency Yellow BB detected twice and classified as unkown as well Testing in simulations (CarMaker map not customizable, FSDS depth map not correct) Plans: Fusion pipepline running with high accuracy Start up scripts running for all sensors and perception Modular code with one param for environment (simulator / bot / actual car map) and one param for sensor stack SIFT on GPU What we did in 2022-23 Everything is over here | FS2023 DV Google drive Initial Plan Explore all different pipelines and see their latencies and accuracies For FSAI'23: Run mono on BB on all simulators and real life (it worked everywhere except FSDS) What wasn't going well SIFT latency was too high and in general also, stereo accuracy isnt very good Major chunk of problems were also realised in sensor integration and trying to run the sensors and take images from ROS Perception wasnt running on all simulators (FSDS initially had) How we tried to resolve it Come up with new and improved pipelines for eg: Slender BB in SIFT for removing outliers on the road Mono using BB Top 1 keypoint in sift to improve accuracy Results TEST ANALYSIS RESULTS DATABASE Challenges faced Finding out what code to write and how Necessary dependencies and their usage Analysis of results using SLAM and on simulators What could be done next? Fusion New research on deep learning based depth estimation SIFT on GPU Algorithms explored till now written by Yash Rampuria","title":"Overview"},{"location":"perception/overview/#overview","text":"Takes in data from LiDAR and ZED2i stereo cams (have to choose between taking from 2 stereocams or 1 stereocam), find class, depth and bearing of cone and send this to SLAM Pipelines for depth estimation: Stereo (Running) Mono using PnP (Running, not very good) Mono using BB height + stereo for edge cases (Running) Lidar only (To be developed) Lidar Mono fusion (Running, although very bad) Accuracy: Mono BB height > Stereo > Mono PnP >>>> Lidar fusion Latency: Mono BB height < Mono PnP < Stereo (Lidar unkown) Major issues: SIFT latency Yellow BB detected twice and classified as unkown as well Testing in simulations (CarMaker map not customizable, FSDS depth map not correct) Plans: Fusion pipepline running with high accuracy Start up scripts running for all sensors and perception Modular code with one param for environment (simulator / bot / actual car map) and one param for sensor stack SIFT on GPU","title":"Overview"},{"location":"perception/overview/#what-we-did-in-2022-23","text":"Everything is over here | FS2023 DV Google drive","title":"What we did in 2022-23"},{"location":"perception/overview/#initial-plan","text":"Explore all different pipelines and see their latencies and accuracies For FSAI'23: Run mono on BB on all simulators and real life (it worked everywhere except FSDS)","title":"Initial Plan"},{"location":"perception/overview/#what-wasnt-going-well","text":"SIFT latency was too high and in general also, stereo accuracy isnt very good Major chunk of problems were also realised in sensor integration and trying to run the sensors and take images from ROS Perception wasnt running on all simulators (FSDS initially had)","title":"What wasn't going well"},{"location":"perception/overview/#how-we-tried-to-resolve-it","text":"Come up with new and improved pipelines for eg: Slender BB in SIFT for removing outliers on the road Mono using BB Top 1 keypoint in sift to improve accuracy","title":"How we tried to resolve it"},{"location":"perception/overview/#results","text":"TEST ANALYSIS RESULTS DATABASE","title":"Results"},{"location":"perception/overview/#challenges-faced","text":"Finding out what code to write and how Necessary dependencies and their usage Analysis of results using SLAM and on simulators","title":"Challenges faced"},{"location":"perception/overview/#what-could-be-done-next","text":"Fusion New research on deep learning based depth estimation SIFT on GPU","title":"What could be done next?"},{"location":"perception/overview/#algorithms-explored-till-now","text":"written by Yash Rampuria","title":"Algorithms explored till now"},{"location":"sysint/can/","text":"Overview CAN(Controller Area Network) Standard CAN uses an 11-bit identifier for different messages, which comes to a total of 211, i.e. 2048, different message IDs. CAN was later modified; the identifier was expanded to 29 bits, giving 229 identifiers. This is called Extended CAN. CAN uses a multi-master bus, where all messages are broadcast on the entire network. The identifiers provide a message priority for arbitration. Working of CAN The driver's input initially sees a '1' and complements this to a zero, which is placed on CANH. CANL sees the complement of CANH and goes high. Notice that the CANH and CANL voltages are offset from one another. During time t1, CANH \u2013 CANL is very close to zero, since CANH and CANL are almost the same voltage. This period, where the driver is sending a logic '1' resulting in CANH and CANL being close to the same voltage, is what we call the CAN recessive state. Priority Arbitration In a Controller Area Network (CAN), lower 11-bit identifiers indicate higher message priority. Nodes both send and monitor the bus. If a node sends recessive bits (logic '1') but detects a dominant bit (logic '0') on the bus, it backs off. This non-destructive arbitration ensures that higher-priority messages can continue uninterrupted. In essence, recessive bits lose to dominant bits, aligning with lower identifier values indicating higher priority. It guarantees the successful transmission of the highest-priority message while maintaining data integrity. What we did before the competition Used Virtual CAN in linux to decode and check CAN transmission using FSAI .dbc file. Established CAN communication of ECD board with Jetson using USB-CAN converter in Linux using Arduino IDE What we did during the competition Had to use InCarPc as Jetson did not work and replaced the CAN cable to PCAN to resolve transmission issues Used the Cantools library in python to make our API which interfaces with the car Wrote the inspection and Autonomous demo codes which is required before participating in any dynamic event Inspection codes went well but in the autonomous demo we had to turn steering left right and then center which we missed!! Plan ahead Describe the tasks to pe performed in this year written by Madhav Gupta","title":"CAN"},{"location":"sysint/can/#overview","text":"CAN(Controller Area Network) Standard CAN uses an 11-bit identifier for different messages, which comes to a total of 211, i.e. 2048, different message IDs. CAN was later modified; the identifier was expanded to 29 bits, giving 229 identifiers. This is called Extended CAN. CAN uses a multi-master bus, where all messages are broadcast on the entire network. The identifiers provide a message priority for arbitration.","title":"Overview"},{"location":"sysint/can/#working-of-can","text":"The driver's input initially sees a '1' and complements this to a zero, which is placed on CANH. CANL sees the complement of CANH and goes high. Notice that the CANH and CANL voltages are offset from one another. During time t1, CANH \u2013 CANL is very close to zero, since CANH and CANL are almost the same voltage. This period, where the driver is sending a logic '1' resulting in CANH and CANL being close to the same voltage, is what we call the CAN recessive state.","title":"Working of CAN"},{"location":"sysint/can/#priority-arbitration","text":"In a Controller Area Network (CAN), lower 11-bit identifiers indicate higher message priority. Nodes both send and monitor the bus. If a node sends recessive bits (logic '1') but detects a dominant bit (logic '0') on the bus, it backs off. This non-destructive arbitration ensures that higher-priority messages can continue uninterrupted. In essence, recessive bits lose to dominant bits, aligning with lower identifier values indicating higher priority. It guarantees the successful transmission of the highest-priority message while maintaining data integrity.","title":"Priority Arbitration"},{"location":"sysint/can/#what-we-did-before-the-competition","text":"Used Virtual CAN in linux to decode and check CAN transmission using FSAI .dbc file. Established CAN communication of ECD board with Jetson using USB-CAN converter in Linux using Arduino IDE","title":"What we did before the competition"},{"location":"sysint/can/#what-we-did-during-the-competition","text":"Had to use InCarPc as Jetson did not work and replaced the CAN cable to PCAN to resolve transmission issues Used the Cantools library in python to make our API which interfaces with the car Wrote the inspection and Autonomous demo codes which is required before participating in any dynamic event Inspection codes went well but in the autonomous demo we had to turn steering left right and then center which we missed!!","title":"What we did during the competition"},{"location":"sysint/can/#plan-ahead","text":"Describe the tasks to pe performed in this year written by Madhav Gupta","title":"Plan ahead"},{"location":"sysint/docker/","text":"Docker Why docker? Working on Linux Working on windows Frequently used commands Future work Why docker? Docker is like a virtual environment emulating hardware and software requirements. It builds an image that contains all the required packages for running a certain application. Different computers have different hardware which can run into different kinds of issues that are hard and cumbersome to debug. Docker helps us with that issue as the hardware and software requirements are also packaged with the application, so if a certain application works inside a certain machine with docker then we can be fairly confident that it will work the same on the other machine. More info on docker Current Usages Currently, docker is implemented inside Github actions ( More info ) where we automated the task of checking if any of the updates in any subsystem's code isn't breaking the whole codebase. Whenever a new push event occurs in our github repo github actions pulls our pre-built docker image containing all the required dependencies and tries to catkin build the workspace and notify us if any error occurs. Working on Linux Installation on ubuntu sudo apt-get update sudo apt-get install ca-certificates curl gnupg sudo install -m 0755 -d /etc/apt/keyrings curl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo gpg --dearmor -o /etc/apt/keyrings/docker.gpg sudo chmod a+r /etc/apt/keyrings/docker.gpg echo \"deb [arch=\"$(dpkg --print-architecture)\" signed-by=/etc/apt/keyrings/docker.gpg] https://download.docker.com/linux/ubuntu \"$(. /etc/os-release && echo \"$VERSION_CODENAME\")\" stable\" | sudo tee /etc/apt/sources.list.d/docker.list > /dev/null sudo apt-get update sudo apt-get install docker-ce docker-ce-cli containerd.io docker-buildx-plugin docker-compose-plugin Detailed installation Enabling GUI Our work requires us to use GUI which is not supported by default, to enable it use # Enable the xhost using (use this every time you boot up your computer) sudo xhost +local:docker sudo docker run -dt --env=\"DISPLAY\" --env=\"QT_X11_MITSHM=1\" --volume=\"/tmp/.X11-unix:/tmp/.X11-unix:rw\" --device=/dev/dri:/dev/dri --name dv (image name) bash For Windows the enabling display will be different but much easier Working on Windows Working on Windows is a little easier and more GUI based, although I would not recommend using Github desktop unless it is absolutely important Installation on Windows Install the docker desktop application as there is no other way, still don\u2019t use the application itself just let it run in the background and do all your stuff in the PowerShell, the commands are the same just don't use sudo (also keep docker desktop running in the background while using docker) Enabling GUI Firstly you have to install Xming on your PC - Download Xming Refer to this video for the next steps - Video Guide (Warning: this video uses GUI to run docker containers, I would recommend doing it with the terminal) - Do \u201cdocker build .\u201d this will create a new image with display enabled - Do \u201cdocker images\u201d then copy the image id - Do \u201cdocker run -dt \u2014name dv pyrodocker/driverless:base_build bash\u201d - check if the container is running or not, if not then do \u201cdocker start image_name\u201d - then do \u201cdocker exec -it image_name bash\u201d - source the iitbdv repo too Frequently used docker commands Docker Pull Pulls any docker image from docker hub sudo docker pull pyrodocker/driverless:base_build more info on docker pull Docker Push Push the image you have created to your docker hub repository sudo docker push [image_tag]:[version] more info on docker push Docker run It creates a running docker container of the given docker image sudo docker run -dt --name dv pyrodocker/driverless:base_build bash more info docker run Docker exec It enters the running docker container sudo docker exec -it dv bash more info docker exec Docker start It starts the docker container sudo docker start dv more info docker start Docker stop It stops the docker container sudo docker stop dv more info docker stop Docker ps It lists out all the running docker containers sudo docker ps In order to see both running and stopped docker containers use the -a tag for all sudo docker ps -a more info docker ps Docker build It builds a docker image from the dockerfile sudo docker build . more info dockerfile \\ more info docker build Other Commands images - lists all the pulled images sudo docker images rm - deletes a docker container sudo docker rm dv rmi - deletes an docker image sudo docker rmi pyrodocker/driverless:base_build tag - changes the name of docker container sudo docker tag (current name) (new name) For more info on different types of commands used in docker refer to this - Github Cheatsheet Future work Our understanding of docker is still in newbie phase. There is a lot of potential in docker. - Being able to do very basic level of work from OSs other than Ubuntu 20.04 - Being able to communicate with host will help with building simulators - More advance automations through github actions written by bhaskar","title":"Docker"},{"location":"sysint/docker/#docker","text":"Why docker? Working on Linux Working on windows Frequently used commands Future work","title":"Docker"},{"location":"sysint/docker/#why-docker","text":"Docker is like a virtual environment emulating hardware and software requirements. It builds an image that contains all the required packages for running a certain application. Different computers have different hardware which can run into different kinds of issues that are hard and cumbersome to debug. Docker helps us with that issue as the hardware and software requirements are also packaged with the application, so if a certain application works inside a certain machine with docker then we can be fairly confident that it will work the same on the other machine. More info on docker","title":"Why docker?"},{"location":"sysint/docker/#current-usages","text":"Currently, docker is implemented inside Github actions ( More info ) where we automated the task of checking if any of the updates in any subsystem's code isn't breaking the whole codebase. Whenever a new push event occurs in our github repo github actions pulls our pre-built docker image containing all the required dependencies and tries to catkin build the workspace and notify us if any error occurs.","title":"Current Usages"},{"location":"sysint/docker/#working-on-linux","text":"","title":"Working on Linux"},{"location":"sysint/docker/#installation-on-ubuntu","text":"sudo apt-get update sudo apt-get install ca-certificates curl gnupg sudo install -m 0755 -d /etc/apt/keyrings curl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo gpg --dearmor -o /etc/apt/keyrings/docker.gpg sudo chmod a+r /etc/apt/keyrings/docker.gpg echo \"deb [arch=\"$(dpkg --print-architecture)\" signed-by=/etc/apt/keyrings/docker.gpg] https://download.docker.com/linux/ubuntu \"$(. /etc/os-release && echo \"$VERSION_CODENAME\")\" stable\" | sudo tee /etc/apt/sources.list.d/docker.list > /dev/null sudo apt-get update sudo apt-get install docker-ce docker-ce-cli containerd.io docker-buildx-plugin docker-compose-plugin Detailed installation","title":"Installation on ubuntu"},{"location":"sysint/docker/#enabling-gui","text":"Our work requires us to use GUI which is not supported by default, to enable it use # Enable the xhost using (use this every time you boot up your computer) sudo xhost +local:docker sudo docker run -dt --env=\"DISPLAY\" --env=\"QT_X11_MITSHM=1\" --volume=\"/tmp/.X11-unix:/tmp/.X11-unix:rw\" --device=/dev/dri:/dev/dri --name dv (image name) bash For Windows the enabling display will be different but much easier","title":"Enabling GUI"},{"location":"sysint/docker/#working-on-windows","text":"Working on Windows is a little easier and more GUI based, although I would not recommend using Github desktop unless it is absolutely important","title":"Working on Windows"},{"location":"sysint/docker/#installation-on-windows","text":"Install the docker desktop application as there is no other way, still don\u2019t use the application itself just let it run in the background and do all your stuff in the PowerShell, the commands are the same just don't use sudo (also keep docker desktop running in the background while using docker)","title":"Installation on Windows"},{"location":"sysint/docker/#enabling-gui_1","text":"Firstly you have to install Xming on your PC - Download Xming Refer to this video for the next steps - Video Guide (Warning: this video uses GUI to run docker containers, I would recommend doing it with the terminal) - Do \u201cdocker build .\u201d this will create a new image with display enabled - Do \u201cdocker images\u201d then copy the image id - Do \u201cdocker run -dt \u2014name dv pyrodocker/driverless:base_build bash\u201d - check if the container is running or not, if not then do \u201cdocker start image_name\u201d - then do \u201cdocker exec -it image_name bash\u201d - source the iitbdv repo too","title":"Enabling GUI"},{"location":"sysint/docker/#frequently-used-docker-commands","text":"","title":"Frequently used docker commands"},{"location":"sysint/docker/#docker-pull","text":"Pulls any docker image from docker hub sudo docker pull pyrodocker/driverless:base_build more info on docker pull","title":"Docker Pull"},{"location":"sysint/docker/#docker-push","text":"Push the image you have created to your docker hub repository sudo docker push [image_tag]:[version] more info on docker push","title":"Docker Push"},{"location":"sysint/docker/#docker-run","text":"It creates a running docker container of the given docker image sudo docker run -dt --name dv pyrodocker/driverless:base_build bash more info docker run","title":"Docker run"},{"location":"sysint/docker/#docker-exec","text":"It enters the running docker container sudo docker exec -it dv bash more info docker exec","title":"Docker exec"},{"location":"sysint/docker/#docker-start","text":"It starts the docker container sudo docker start dv more info docker start","title":"Docker start"},{"location":"sysint/docker/#docker-stop","text":"It stops the docker container sudo docker stop dv more info docker stop","title":"Docker stop"},{"location":"sysint/docker/#docker-ps","text":"It lists out all the running docker containers sudo docker ps In order to see both running and stopped docker containers use the -a tag for all sudo docker ps -a more info docker ps","title":"Docker ps"},{"location":"sysint/docker/#docker-build","text":"It builds a docker image from the dockerfile sudo docker build . more info dockerfile \\ more info docker build","title":"Docker build"},{"location":"sysint/docker/#other-commands","text":"images - lists all the pulled images sudo docker images rm - deletes a docker container sudo docker rm dv rmi - deletes an docker image sudo docker rmi pyrodocker/driverless:base_build tag - changes the name of docker container sudo docker tag (current name) (new name) For more info on different types of commands used in docker refer to this - Github Cheatsheet","title":"Other Commands"},{"location":"sysint/docker/#future-work","text":"Our understanding of docker is still in newbie phase. There is a lot of potential in docker. - Being able to do very basic level of work from OSs other than Ubuntu 20.04 - Being able to communicate with host will help with building simulators - More advance automations through github actions written by bhaskar","title":"Future work"},{"location":"sysint/overview/","text":"Overview What we did in 2022-23 During 2022-23 we worked on alot of things, few of them are mentioned below: Setting up ROS communication between various nodes. Researching and setting up CAN communication and socketCAN Testing our pipelines on simulators Sensor Integration into our algorithm The most time consuming of all, solving bt(s) along the way TL;DR: Integrated the system Initial Plan Our work resembeled our initial plan quite well, with the goal of succesfully running our pipeline together along with sensors. Along with this we planned to include the CAN API provided by FSAI to include in our code for communication with CAN, but instead we used our own python code to do this (discussed under the section of what wasn't going well); we planned to utilise CarMaker (one of the simulator we use) to its fullest potential; we also planned to run our entire pipeline on atleast one of the simulator to produce satifactory results. The results we obtained looked like this Here these blue patches are the poition of cones with their variance. What wasn't going well Well for starters, nothing ever went well (a sentence which seems to be always true for SysInt), the major L's were as follows CarMaker does not publishes the global velocity and yaws of the car, so we had to change the code of the CarMaker node. CarMaker still does not publishes the global coordinates of the cones, instead it defines the position of cones wrt the predefined path (called \"route\") of the vehicle. CAN communication hardware setup remained a pain in the ass for a long time. Results WILL ADD PICTURES and VIDEOS The good ~Explain the good things/postive things about the algorithm and/or out implementation of it.~ Not empty by choice The bad Will Add This Part Later, NGL it would be the major chunk What could be done next? ! The moment I begin contemplating potential next steps, I find myself inundated with a deluge of countless creative ideas. Envisioned for the future are a set of foundational enhancements that merit our diligent attention and efforts: Moving onto ROS2 as that seems to be the road ahead, with noetic about to reach its EOL, I see no point in continuing with ROS1 any further. During our talk with different teams in FSAI we found out that there are subdivisions in some teams that have the job of making life easier for the other members, from developing GUIs to automation of ROS to even developing cloud based substitute for GitHub. Using CarMaker to its fullest potential, which include testing Jetson with CM communicating through CAN Developing our own simulator will be the need of the future, and should be looked into written by Mohak Vyas","title":"Overview"},{"location":"sysint/overview/#overview","text":"","title":"Overview"},{"location":"sysint/overview/#what-we-did-in-2022-23","text":"During 2022-23 we worked on alot of things, few of them are mentioned below: Setting up ROS communication between various nodes. Researching and setting up CAN communication and socketCAN Testing our pipelines on simulators Sensor Integration into our algorithm The most time consuming of all, solving bt(s) along the way TL;DR: Integrated the system","title":"What we did in 2022-23"},{"location":"sysint/overview/#initial-plan","text":"Our work resembeled our initial plan quite well, with the goal of succesfully running our pipeline together along with sensors. Along with this we planned to include the CAN API provided by FSAI to include in our code for communication with CAN, but instead we used our own python code to do this (discussed under the section of what wasn't going well); we planned to utilise CarMaker (one of the simulator we use) to its fullest potential; we also planned to run our entire pipeline on atleast one of the simulator to produce satifactory results. The results we obtained looked like this Here these blue patches are the poition of cones with their variance.","title":"Initial Plan"},{"location":"sysint/overview/#what-wasnt-going-well","text":"Well for starters, nothing ever went well (a sentence which seems to be always true for SysInt), the major L's were as follows CarMaker does not publishes the global velocity and yaws of the car, so we had to change the code of the CarMaker node. CarMaker still does not publishes the global coordinates of the cones, instead it defines the position of cones wrt the predefined path (called \"route\") of the vehicle. CAN communication hardware setup remained a pain in the ass for a long time.","title":"What wasn't going well"},{"location":"sysint/overview/#results","text":"WILL ADD PICTURES and VIDEOS","title":"Results"},{"location":"sysint/overview/#the-good","text":"~Explain the good things/postive things about the algorithm and/or out implementation of it.~ Not empty by choice","title":"The good"},{"location":"sysint/overview/#the-bad","text":"Will Add This Part Later, NGL it would be the major chunk","title":"The bad"},{"location":"sysint/overview/#what-could-be-done-next","text":"! The moment I begin contemplating potential next steps, I find myself inundated with a deluge of countless creative ideas. Envisioned for the future are a set of foundational enhancements that merit our diligent attention and efforts: Moving onto ROS2 as that seems to be the road ahead, with noetic about to reach its EOL, I see no point in continuing with ROS1 any further. During our talk with different teams in FSAI we found out that there are subdivisions in some teams that have the job of making life easier for the other members, from developing GUIs to automation of ROS to even developing cloud based substitute for GitHub. Using CarMaker to its fullest potential, which include testing Jetson with CM communicating through CAN Developing our own simulator will be the need of the future, and should be looked into written by Mohak Vyas","title":"What could be done next?"}]}